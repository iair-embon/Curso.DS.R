---
title: "TrabajoFinal_Genero"
author: "Alejandro Ramos Usaj, Agostina Sacson y Iair Embon"
date: '2022-07-25'
output: html_document
---

```{r}
library(tidyverse)
library(glmnet)
```

Cargo los datos
```{r}
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())

# load the function to get the df list
load("./df_total_filtered.Rda")
```

Preproceso la varible genero
```{r}
d$gender <- ifelse(d$gender == "Masculino",1,0)
```

Corremos una regresion logistica para predecir genero con los dominios de los rasgos disfuncionales de la personalidad

```{r}
model <- glm(gender ~ DomainAntagonism + 
               DomainDetachment +
               DomainDisinhibition +
               DomainNegativeAffect + 
               DomainPsychoticism,
             family=binomial(link='logit'),
             data=d)
summary(model)
```

Corro otro modelo logistico pero esta vez controlo por edad
```{r}
model2 <- glm(gender ~ DomainAntagonism + 
               DomainDetachment +
               DomainDisinhibition +
               DomainNegativeAffect + 
               DomainPsychoticism +
               age,
             family=binomial(link='logit'),
             data=d)
summary(model2)
```

#Regresion logistica usando metodos de regularizaciones

Corro una regresion logistica para predecir genero usando tres metodos de regularizacion (ridge, lasso, elastic net), para predecir facetas.
Por otro lado, es importante para estas regularizaciones, elegir un lambda adecuado, el cual se suele elegir mediante algun metodo de cross validation. Usualmente, en los trabajos que revisamos, usan 10 fold corss validation, aunque por la poca cantidad de datos usaremos leave one out cross validation (LOOCV). Para eso crearemos nuestra propia funcion de LOOCV

Creo una funcion para realizar un LOOCV y elegir asi el valor de lambda optimo.

```{r}
#### 

LOOCV.fun.glmnet <- function(df, alpha.dado){
  ### Primero creo una secuencua de posibles lambdas, desde un modelo desechable
  
  # Guardo las observaciones de genero
  y <- df$gender

  # ahora les saco genero y Participant (ya que no tienen que ir como predictores)
  df.lambda <- df %>% select(!c(gender,Participant))

  # transformo en matrix
  df.lambda.m <- df.lambda %>% data.matrix()

  # Corro el modelo y obtengo el lambda
  modelo.lambda <- glmnet(df.lambda.m, y , family = "binomial",
                            alpha = alpha.dado)
  posibles_lambdas <- modelo.lambda$lambda
  
  # creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
  matriz.errores <- matrix(data=NA,nrow= nrow(df),
                           ncol= length(posibles_lambdas))
  
  for (j in 1:nrow(df)){
    # datos de entrenamiento (todos menos 1)
    train <- df %>%
      filter(Participant != df$Participant[j])
    
    # agarro el dato que quedo para el testeo
    test  <- anti_join(df, train, by = 'Participant')
    
    # Guardo las observaciones de genero en entrenamiento y testeo (para entrenar el modelo y testearlo)
    y.train <- train$gender
    y.test <- test$gender
    
    # ahora les saco genero y Participant (ya que no tienen que ir como predictores)
    train <- train %>% select(!c(gender,Participant))
    test <- test %>% select(!c(gender,Participant))
    
    # transformo en matrix
    train.m <- train %>% data.matrix()
    test.m <- test %>% data.matrix()
    
    # corro el modelo con los datos de entrenamiento
    modelo <- glmnet(train.m, y.train, family = "binomial",
                            alpha = alpha.dado, lambda = posibles_lambdas)
    
    # hago prediccion sobre la data de testeo
    probabilities <- modelo %>% predict(newx = test.m, type = "response")
    predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
    # Model accuracy
    matriz.errores[j,] <- predicted.classes == y.test
  }
  
  # saco los root mean squared errors para cada lambda (en principio, solo vamos a usar accuracy)
  # lambda.RMSE <- sqrt(((rowSums(matriz.errores))**2)/nrow(df))
  
  list_return <- list("matriz.errores" = matriz.errores,
                      "lambdas" = posibles_lambdas)
  
  return(list_return)
}

```

#Para facetas

Primero saco algunas variables que no van a ser necesarias.

```{r}

# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
  select(!c(DomainNegativeAffect,
            DomainDetachment,
            DomainAntagonism,
            DomainDisinhibition,
            DomainPsychoticism,
            PC,
            ConfMean,
            ConfSD,
            ReacTimeMean_DiscTask,
            ReacTimeSD_DiscTask,
            ReacTimeMean_ConfTask,
            ReacTimeSD_ConfTask,
            mc,
            ConfMean.norm,
            overconfidence))

```

Ajusto una regresion con penalizacion Ridge. 

```{r, warning=F}
lambdaOptimo_facetas_ridge <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0)

# lo ploteo
matriz.errores <- lambdaOptimo_facetas_ridge$matriz.errores
matriz.errores %>% apply(2, mean) %>% plot(type ='l', log = 'x')

# saco la proporcion de aciertos
accuracy_lambdas <- colMeans(matriz.errores)

# tomo el lambda que tiene mayor porporcion de aciertos
index.lambda <- which.max(accuracy_lambdas)
lambda.optimo <- lambdaOptimo_facetas_ridge$lambdas[index.lambda]

### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$gender

# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(gender,Participant))

# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()

# Corro el modelo y obtengo el lambda
modelo.facetas_ridge <- glmnet(d.regre.regul.facetas.prepro.m, y , family = "binomial",
                            alpha = 0, lambda = lambda.optimo)

coef(modelo.facetas_ridge)
```

Ajusto una regresion penalizacion de tipo Lasso

```{r}
lambdaOptimo_facetas_lasso <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 1)

# lo ploteo
matriz.errores <- lambdaOptimo_facetas_lasso$matriz.errores
matriz.errores %>% apply(2, mean) %>% plot(type ='l', log = 'x')

# saco la proporcion de aciertos
accuracy_lambdas <- colMeans(matriz.errores)

# tomo el lambda que tiene mayor porporcion de aciertos
index.lambda <- which.max(accuracy_lambdas)
lambda.optimo <- lambdaOptimo_facetas_lasso$lambdas[index.lambda]

### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$gender

# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(gender,Participant))

# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()

# Corro el modelo y obtengo el lambda
modelo.facetas_lasso <- glmnet(d.regre.regul.facetas.prepro.m, y , family = "binomial",
                            alpha = 1, lambda = lambda.optimo)

coef(modelo.facetas_lasso)
```

Ajusto una Elastic Net

```{r}
lambdaOptimo_facetas_elasticNet <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0.5)

# lo ploteo
matriz.errores <- lambdaOptimo_facetas_elasticNet$matriz.errores
matriz.errores %>% apply(2, mean) %>% plot(type ='l', log = 'x')

# saco la proporcion de aciertos
accuracy_lambdas <- colMeans(matriz.errores)

# tomo el lambda que tiene mayor porporcion de aciertos
index.lambda <- which.max(accuracy_lambdas)
lambda.optimo <- lambdaOptimo_facetas_elasticNet$lambdas[index.lambda]

### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$gender

# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(gender,Participant))

# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()

# Corro el modelo y obtengo el lambda
modelo.facetas_elasticNet <- glmnet(d.regre.regul.facetas.prepro.m, y , family = "binomial",
                            alpha = 0.5, lambda = lambda.optimo)

coef(modelo.facetas_elasticNet)
```


# Dominios

Armo un vector con los nombres de las columnas que contienen las variables de interes para el caso de los dominios.

```{r}
domain_columns <- colnames(d)[str_detect(colnames(d), pattern = 'Domain')]
```

Genero un vector con las formulas de todos los posibles modelos que pueden generarse a partir de los 5 dominios a utilizar como covariadas. La cantidad total de modelos posibles es $\sum_{k = 1}^n\frac{n!}{k!(n-k)!}$ que para este caso nos da 31.

```{r}
mejor_subconjunto <- sapply(
  1:5, function(x) combn(domain_columns, x, simplify = F) %>% 
                 lapply(function(y) str_flatten(y, ' + ')) %>% 
                 unlist()
       )  %>% unlist() %>%
  sapply(
    function(x) paste0('overconfidence ~ ', x) 
  ) %>% unname()
```

Generamos dos vectores, una que contenga las formulas de un modelo simple (de un solo predictor) y otro que contenga la formula del modelo completo (con todos los predictores).

```{r}
formula_dominio_simple <- mejor_subconjunto[1:5]
formula_dominio_completa <- mejor_subconjunto[length(mejor_subconjunto)]
```

Calcular los coeficientes $\beta$ para cada predictor en el caso del modelo simple (con un solo predictor) y en el caso del modelo completo (con todos los predictores). Para cada caso estimar, usando 10000 muestras bootstrap no parametricas, la media y el intervalo del 95% de confianza para cada coeficiente $\beta$ y guardarlo en un dataframe llamado `bootstrap_dominio`

```{r}
set.seed(1234)
bootstrap_dominio <- sapply(
  c(formula_dominio_simple,formula_dominio_completa),
  function(x) replicate(10,
  glm(as.formula(x), family = binomial(link = 'logit'),
      data = slice_sample(d, n =nrow(d), replace = T)
      )$coeff 
) %>%
  apply(
    1, 
    FUN = function(x.row) c(media = mean(x.row), 
                            quantile(x.row, c(0.025,0.975))
                            )
    )
) %>% lapply(as.data.frame) %>% bind_rows() %>%
  mutate(
    tipo_modelo = rep(
      c('simple','completo'), c(3*5,3)
      )
         ) %>% 
  rownames_to_column(var = 'tipo_medicion') %>%
  mutate(tipo_medicion = str_replace(tipo_medicion, 'media\\d|\\...\\d+','')) %>% 
  pivot_longer(!starts_with('tipo'), names_to = 'coeficiente', values_to = 'estimacion') %>%
  drop_na() %>%
  filter(coeficiente != '(Intercept)') %>%
  pivot_wider(names_from = tipo_medicion, values_from = estimacion)
```

Graficar los valores de los coeficientes con sus respectivos intervalos para cada predictor indicando con un color si la estimacion proviene de los modelos simples o del modelo completo e indicando con una linea punteada el valor de 0 en el grafico. 

```{r}
bootstrap_dominio %>%
  ggplot(
    aes(x = coeficiente, y = media, color = tipo_modelo, ymin = `2.5%`, ymax = `97.5%`)
  ) +
  geom_point(
    position = position_dodge(.8)
  ) +
  geom_errorbar(
    width = .2,
    position = position_dodge(.8)
  ) +
  geom_hline(yintercept = 0) +
  coord_flip() +
  ylab('Estimacion') + xlab('Coeficientes') +
  scale_color_discrete('Tipo de Modelo', labels = c('Multiple', 'Simple'))
```

Interpretar los resultados

Evaluar un ajuste polinomial para la regresion logistica generando una grilla de posibles valores para el grado del polinomio que vaya de 1 a 15 (con intervalos de 1) y ajustar el modelo usando la funcion `poly`. Para cada grado posible del polinomio utilizar un procedimiento leave-one-out para calcular el accuracy y elegir asi el grado optimo del polinomio a utilizar.

```{r, warning=FALSE}
grilla_grado <- expand.grid(indice = 1:nrow(d), grado = 1:15)

spam <- grilla_grado %>% mutate(
  probabilidad = grilla_grado %>% 
    pmap(
      ~ glm(overconfidence ~ poly(DomainDisinhibition, .y), family = binomial(link = 'logit'),
            data = d[-.x, ]
            ) %>% 
        predict(d[.x, ], type = 'response')
      ) %>% 
    unlist(),
  prediccion = ifelse(probabilidad > 0.5, 1, 0),
  acierto = prediccion == d[indice, 'overconfidence']
  ) %>% group_by(grado) %>% summarise(accuracy = mean(acierto))

spam %>%
  ggplot(
    aes(x = grado, y = accuracy)
  ) + geom_smooth(span = 0.3) +
  geom_hline(
    yintercept = d %>% count(overconfidence) %>% mutate(n = n/sum(n)) %>% pull(n) %>% max(),
    linetype = 'dashed'
  )
```

Utilizando el vector `mejor_subconjunto` emplear el procedimiento leave-one-out para elegir el modelo con mejor capacidad predictiva de todos los posibles.

```{r}
predicciones_mejor_subconjunto <- pmap(
  expand.grid(1:nrow(d), mejor_subconjunto) %>% mutate(Var2 = as.character(Var2)),
  ~ glm(
      as.formula(.y), family = binomial(link = 'logit'), data = d, subset = -.x
    ) %>% predict(d[.x, ], type = 'response')
) %>%
  unlist()

resultado_mejor_subconjunto <- expand.grid(1:nrow(d), mejor_subconjunto) %>%
  mutate(pred = predicciones_mejor_subconjunto,
         respuesta = ifelse(pred > 0.5, 1, 0),
         acierto = as.numeric(respuesta == d[Var1, 'overconfidence'])) %>%
  ggplot(
  aes(x = Var2, y = acierto)
) +
  stat_summary(geom = 'pointrange') +
  coord_flip() +
  theme(axis.text.y = element_text(size = 5))
```

Representar en una tabla sus estimaciones puntuales con un intervalo de confianza del 95% construido a partir de 10000 muestras bootstrap no parametricas. 

