---
title: "TrabajoFinal_Genero"
author: "Alejandro Ramos Usaj, Agostina Sacson y Iair Embon"
date: '2022-07-25'
output: html_document
---

```{r}
library(tidyverse)
library(glmnet)
```

Cargo los datos
```{r}
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())

# load the function to get the df list
load("./df_total_filtered.Rda")
```

Convierto el df por trials en un df por participantes

```{r}
d <- df_total %>%
  select(!c(RelyOn,
            Problems,
            ConfKey1,
            ConfKey2,
            ConfKey3,
            ConfKey4,
            discrimination_is_correct,
            confidence_key,
            trials,
            PointDifference,
            ReacTime_DiscTask,
            ReacTime_ConfTask)) %>%
  distinct(Participant,.keep_all = TRUE)
```


Preproceso la varible genero
```{r}
d$gender <- ifelse(d$gender == "Masculino",1,0)
```


#Regresion logistica usando metodos de regularizaciones

Corro una regresion logistica para predecir genero usando tres metodos de regularizacion (ridge, lasso, elastic net), para predecir facetas.
Por otro lado, es importante para estas regularizaciones, elegir un lambda adecuado, el cual se suele elegir mediante algun metodo de cross validation. Usualmente, en los trabajos que revisamos, usan 10 fold corss validation, aunque por la poca cantidad de datos usaremos leave one out cross validation (LOOCV). Para eso crearemos nuestra propia funcion de LOOCV

Creo una funcion para realizar un LOOCV y elegir asi el valor de lambda optimo.

```{r}
#### 

LOOCV.fun.glmnet <- function(df, alpha.dado){
  ### Primero creo una secuencua de posibles lambdas, desde un modelo desechable
  
  # Guardo las observaciones de genero
  y <- df$gender

  # ahora les saco genero y Participant (ya que no tienen que ir como predictores)
  df.lambda <- df %>% select(!c(gender,Participant))

  # transformo en matrix
  df.lambda.m <- df.lambda %>% data.matrix()

  # Corro el modelo y obtengo el lambda
  modelo.lambda <- glmnet(df.lambda.m, y , family = "binomial",
                            alpha = alpha.dado)
  posibles_lambdas <- modelo.lambda$lambda
  
  # creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
  matriz.errores <- matrix(data=NA,nrow= nrow(df),
                           ncol= length(posibles_lambdas))
  
  for (j in 1:nrow(df)){
    # datos de entrenamiento (todos menos 1)
    train <- df %>%
      filter(Participant != df$Participant[j])
    
    # agarro el dato que quedo para el testeo
    test  <- anti_join(df, train, by = 'Participant')
    
    # Guardo las observaciones de genero en entrenamiento y testeo (para entrenar el modelo y testearlo)
    y.train <- train$gender
    y.test <- test$gender
    
    # ahora les saco genero y Participant (ya que no tienen que ir como predictores)
    train <- train %>% select(!c(gender,Participant))
    test <- test %>% select(!c(gender,Participant))
    
    # transformo en matrix
    train.m <- train %>% data.matrix()
    test.m <- test %>% data.matrix()
    
    # corro el modelo con los datos de entrenamiento
    modelo <- glmnet(train.m, y.train, family = "binomial",
                            alpha = alpha.dado, lambda = posibles_lambdas)
    
    # hago prediccion sobre la data de testeo
    probabilities <- modelo %>% predict(newx = test.m, type = "response")
    predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
    # Model accuracy
    matriz.errores[j,] <- predicted.classes == y.test
  }
  
  # saco los root mean squared errors para cada lambda (en principio, solo vamos a usar accuracy)
  # lambda.RMSE <- sqrt(((rowSums(matriz.errores))**2)/nrow(df))
  
  list_return <- list("matriz.errores" = matriz.errores,
                      "lambdas" = posibles_lambdas)
  
  return(list_return)
}

```

#Para facetas

Primero saco algunas variables que no van a ser necesarias.

```{r}

# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
  select(!c(DomainNegativeAffect,
            DomainDetachment,
            DomainAntagonism,
            DomainDisinhibition,
            DomainPsychoticism,
            PC,
            ConfMean,
            ConfSD,
            ReacTimeMean_DiscTask,
            ReacTimeSD_DiscTask,
            ReacTimeMean_ConfTask,
            ReacTimeSD_ConfTask,
            mc))

```


Creo una funcion que tome la funcion que elige el lambda optimo y que lo use en una regresion con un determindo alpha optimizado

```{r}
opt_alpha_lambda <- function(df){
  
  # Creo los vectores que van a contener todos los lambdas, alphas y sus respectivos accuracy
  alphas.usados <- c()
  lambdas.usados <- c()
  accuracy <- c()
  
  # creo los alphas que vamos a usar
  muchos.alphas <- seq(0,1, by = 0.1)
  
  # itero por varios alphas
  for (i in 1:length(muchos.alphas)) {
    alpha.dado <- muchos.alphas[i]
    
    # Hago LOOCV para elegir varios lambdas
    lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
    
    matriz.errores <- lambdaOptimo_facetas$matriz.errores
    # saco la proporcion de aciertos
    accuracy <- c(accuracy, colMeans(matriz.errores))
    lambdas.usados <- c(lambdas.usados,lambdaOptimo_facetas$lambdas)
    alphas.usados <- c(alphas.usados, rep(alpha.dado, length(lambdaOptimo_facetas$lambdas)))
  }
  
  df_alp_lambd_accuracy <- data.frame(alpha = alphas.usados,
                                  lambda = lambdas.usados,
                                  accuracy = accuracy)
    
  return(df_alp_lambd_accuracy)
}

opt_alpha_lambda.df <- opt_alpha_lambda(d.regre.regul.facetas)

# tomo el lambda que tiene el menor error
index.opt.param <- which.min(opt_alpha_lambda.df$accuracy)
  
# Corro el modelo con el alpha optimo y el lambda que minimiza el error
lambda.optimo <- opt_alpha_lambda.df$lambda[index.opt.param]
alpha.optimo <- opt_alpha_lambda.df$alpha[index.opt.param]  

### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$gender
  
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(gender,Participant))
  
# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()

# Corro el modelo y obtengo el lambda
modelo.facetas <- glmnet(d.regre.regul.facetas.prepro.m, y,
                          family = "binomial",
                          alpha = alpha.optimo, lambda = lambda.optimo)

coef(modelo.facetas)
# me fijo el lambda optimo que me elije el modelo por si solo usando funciones de la libreria, para alpha = 1
modelo.facetas2 <- glmnet(d.regre.regul.facetas.prepro.m, y,
                           family = "binomial",
                           alpha = 0.1)
coef(modelo.facetas2)
plot(modelo.facetas2)
plot(modelo.facetas2, xvar = "dev", label = TRUE)
plot(modelo.facetas2, xvar = "lambda", label = TRUE)
set.seed(1010)
cvfit <- cv.glmnet(d.regre.regul.facetas.prepro.m,y, type.measure = "auc", nfolds = nrow(d.regre.regul.facetas))
cvfit$lambda.min
coef(cvfit, s = "lambda.min")
```


Ajusto una regresion con penalizacion Ridge. 

```{r, warning=F}
lambdaOptimo_facetas_ridge <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0)

# lo ploteo
matriz.errores <- lambdaOptimo_facetas_ridge$matriz.errores
matriz.errores %>% apply(2, mean) %>% plot(type ='l', log = 'x')

# saco la proporcion de aciertos
accuracy_lambdas <- colMeans(matriz.errores)

# tomo el lambda que tiene mayor porporcion de aciertos
index.lambda <- which.max(accuracy_lambdas)
lambda.optimo <- lambdaOptimo_facetas_ridge$lambdas[index.lambda]

### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$gender

# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(gender,Participant))

# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()

# Corro el modelo y obtengo el lambda
modelo.facetas_ridge <- glmnet(d.regre.regul.facetas.prepro.m, y , family = "binomial",
                            alpha = 0, lambda = lambda.optimo)

coef(modelo.facetas_ridge)
```

Ajusto una regresion penalizacion de tipo Lasso

```{r}
lambdaOptimo_facetas_lasso <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 1)

# lo ploteo
matriz.errores <- lambdaOptimo_facetas_lasso$matriz.errores
matriz.errores %>% apply(2, mean) %>% plot(type ='l', log = 'x')

# saco la proporcion de aciertos
accuracy_lambdas <- colMeans(matriz.errores)

# tomo el lambda que tiene mayor porporcion de aciertos
index.lambda <- which.max(accuracy_lambdas)
lambda.optimo <- lambdaOptimo_facetas_lasso$lambdas[index.lambda]

### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$gender

# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(gender,Participant))

# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()

# Corro el modelo y obtengo el lambda
modelo.facetas_lasso <- glmnet(d.regre.regul.facetas.prepro.m, y , family = "binomial",
                            alpha = 1, lambda = lambda.optimo)

coef(modelo.facetas_lasso)
```

Ajusto una Elastic Net

```{r}
lambdaOptimo_facetas_elasticNet <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0.5)

# lo ploteo
matriz.errores <- lambdaOptimo_facetas_elasticNet$matriz.errores
matriz.errores %>% apply(2, mean) %>% plot(type ='l', log = 'x')

# saco la proporcion de aciertos
accuracy_lambdas <- colMeans(matriz.errores)

# tomo el lambda que tiene mayor porporcion de aciertos
index.lambda <- which.max(accuracy_lambdas)
lambda.optimo <- lambdaOptimo_facetas_elasticNet$lambdas[index.lambda]

### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$gender

# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(gender,Participant))

# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()

# Corro el modelo y obtengo el lambda
modelo.facetas_elasticNet <- glmnet(d.regre.regul.facetas.prepro.m, y , family = "binomial",
                            alpha = 0.5, lambda = lambda.optimo)

coef(modelo.facetas_elasticNet)
```


# Dominios

X.2. Generar un nuevo vector llamado `mejor_subconjunto_genero` de la misma manera que en el ejercicio [IGUAL QUE EN EL EJERCICIO CON LA REGRESION LINEAL] modificando unicamente la variable de respuesta por la variable `gender`. 

```{r}
mejor_subconjunto_genero <- sapply(
  1:5, function(x) combn(columnas_de_dominio, x, simplify = F) %>% 
                 lapply(function(y) str_flatten(y, ' + ')) %>% 
                 unlist()
       )  %>% unlist() %>%
  sapply(
    function(x) paste0('gender ~ ', x) 
  ) %>% unname()
```

X.3. Generar dos vectores llamados `formula_simple_genero` y `formula_completa_genero` con la misma logica que en [EL EJERCICIO CON LA LINEAL] utilizando en este caso el vector `mejor_subconjunto_genero`. 

```{r}
formula_simple_genero <- mejor_subconjunto_genero[1:5]
formula_completa_genero <- mejor_subconjunto_genero[length(mejor_subconjunto)]
```

X.4. Modificar la funcion `bootstrap_lineal`, llamandola `bootstrap_logistico`, de manera que haga lo mismo que la funcion original pero empleando un modelo de regresion logistica.

```{r}
bootstrap_logistico <- function(formula_string) {
  replicate(10000,
  glm(as.formula(formula_string), family = binomial(link = 'logit'),
      data = slice_sample(d, n =nrow(d), replace = T)
      )$coeff
  ) %>%
  apply(
    1, 
    FUN = function(x.row) c(media = mean(x.row), 
                            quantile(x.row, c(0.025,0.975))
                            )
  )
}
```

X.5. Evalue el funcionamiento de `bootstrap_logistico` empleando alguna formula que use como variable de respuesta el genero. 

```{r}
bootstrap_logistico('gender ~ age')
```
x.6. Utilizando los vectores `formula_dominio_simple` y `formula_dominio_completa`, itere por cada una de las formulas y en cada caso utilice la funcion `bootstrap_logistico` para calcular los parametros relevantes de la distribucion bootstrap de los coeficientes $\beta$ para cada predictor en el caso del modelo simple (con un solo predictor) y en el caso del modelo completo (con todos los predictores). El resultado debe ser un dataframe donde cada fila corresponda a un coeficiente, indicado por una columna llamada `coeficiente`, identificado por una columna llamada `tipo_modelo` que indica si el coeficiente proviene de un modelo univariado o multivariado y con tres columnas correspondientes a la media, el percentil 2.5 y el percentil 97.5 correspondiente a cada coeficiente. Guardar el dataframe resultante en una variable llamada `bootstrap_dominio`.

```{r}
set.seed(1234)
bootstrap_dominio <- sapply(
  c(formula_dominio_simple,formula_dominio_completa),
  bootstrap_logistico 
  ) %>% lapply(as.data.frame) %>% bind_rows() %>%
  mutate(
    tipo_modelo = rep(
      c('simple','completo'), c(3*5,3)
      )
         ) %>% 
  rownames_to_column(var = 'tipo_medicion') %>%
  mutate(tipo_medicion = str_replace(tipo_medicion, 'media\\d|\\...\\d+','')) %>% 
  pivot_longer(!starts_with('tipo'), names_to = 'coeficiente', values_to = 'estimacion') %>%
  drop_na() %>%
  filter(coeficiente != '(Intercept)') %>%
  pivot_wider(names_from = tipo_medicion, values_from = estimacion)
```

Graficar los valores de los coeficientes con sus respectivos intervalos para cada predictor indicando con un color si la estimacion proviene de los modelos simples o del modelo completo e indicando con una linea punteada el valor de 0 en el grafico. 

```{r}
bootstrap_dominio %>%
  ggplot(
    aes(x = coeficiente, y = media, color = tipo_modelo, ymin = `2.5%`, ymax = `97.5%`)
  ) +
  geom_point(
    position = position_dodge(.8)
  ) +
  geom_errorbar(
    width = .2,
    position = position_dodge(.8)
  ) +
  geom_hline(yintercept = 0) +
  coord_flip() +
  ylab('Estimacion') + xlab('Coeficientes') +
  scale_color_discrete('Tipo de Modelo', labels = c('Multiple', 'Simple'))
```

Interpretar los resultados

Evaluar un ajuste polinomial para la regresion logistica generando una grilla de posibles valores para el grado del polinomio que vaya de 1 a 15 (con intervalos de 1) y ajustar el modelo usando la funcion `poly`. Para cada grado posible del polinomio utilizar un procedimiento leave-one-out para calcular el accuracy y elegir asi el grado optimo del polinomio a utilizar.

```{r, warning=FALSE}
grilla_grado <- expand.grid(indice = 1:nrow(d), grado = 1:15)

spam <- grilla_grado %>% mutate(
  probabilidad = grilla_grado %>% 
    pmap(
      ~ glm(overconfidence ~ poly(DomainDisinhibition, .y), family = binomial(link = 'logit'),
            data = d[-.x, ]
            ) %>% 
        predict(d[.x, ], type = 'response')
      ) %>% 
    unlist(),
  prediccion = ifelse(probabilidad > 0.5, 1, 0),
  acierto = prediccion == d[indice, 'overconfidence']
  ) %>% group_by(grado) %>% summarise(accuracy = mean(acierto))

spam %>%
  ggplot(
    aes(x = grado, y = accuracy)
  ) + geom_smooth(span = 0.3) +
  geom_hline(
    yintercept = d %>% count(overconfidence) %>% mutate(n = n/sum(n)) %>% pull(n) %>% max(),
    linetype = 'dashed'
  )
```

Utilizando el vector `mejor_subconjunto` emplear el procedimiento leave-one-out para elegir el modelo con mejor capacidad predictiva de todos los posibles.

```{r}
predicciones_mejor_subconjunto <- pmap(
  expand.grid(1:nrow(d), mejor_subconjunto) %>% mutate(Var2 = as.character(Var2)),
  ~ glm(
      as.formula(.y), family = binomial(link = 'logit'), data = d, subset = -.x
    ) %>% predict(d[.x, ], type = 'response')
) %>%
  unlist()

resultado_mejor_subconjunto <- expand.grid(1:nrow(d), mejor_subconjunto) %>%
  mutate(pred = predicciones_mejor_subconjunto,
         respuesta = ifelse(pred > 0.5, 1, 0),
         acierto = as.numeric(respuesta == d[Var1, 'overconfidence'])) %>%
  ggplot(
  aes(x = Var2, y = acierto)
) +
  stat_summary(geom = 'pointrange') +
  coord_flip() +
  theme(axis.text.y = element_text(size = 5))
```

Representar en una tabla sus estimaciones puntuales con un intervalo de confianza del 95% construido a partir de 10000 muestras bootstrap no parametricas. 

