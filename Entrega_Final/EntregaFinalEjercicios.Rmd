---
title: 'Guia de Trabajos Practicos: Entrega Final'
output:
  html_notebook: default
  pdf_document: default
---

A lo largo de este trabajo, se estara trabajando con datos de 224 personas adultas, obtenidas mediante una tarea perceptual visual. En dicha tarea, se les peresentaba dos circulos con muchos puntitos, y el participante debia infomar que circulo presentaba una mayor cantidad de puntitos, el de la izquierda o la derecha. Luego de informar esto ultimo, el participante tambien tenia que informar la confianza que tenia en que su respuesta sobre la cantidad de puntitos fuera correcta. La confianza era informada mediante una escala Likert que iba del 1 al 4, siendo 1 baja confianza y 4 alta confianza. Ver " chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://50jaiio.sadio.org.ar/pdfs/agranda/AGRANDA-11.pdf " para una descripcion completa de la tarea. 
Por otro lado, a estos 224 participantes se los evaluo con un test llamado Inventario para Trastornos de la Personalidad para el DSM‐5 (PID-5). Este test evalua 25 facetas o rasgos disfuncionales de la personalidad segun la seccion 3 del manual diagnostico y estadistico de los trastornos de mentales en su 5ta edicion. Un estudio reciente, adapto y valido este test para que pudiera ser utilizado en poblacion Argentina (ver: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7451368/). En este ultmo estudio, tambien se realizo un analisis factorial en donde gran parte de las 25 facetas disfuncionales de personalidad se agrupaban en 5 dominios. 
En el presente trabajo se explorara la confianza en relacion a las facetas y dominos disfuncionales de la personalidad. La confianza tiene muchas medidas, de las cuales se eligio la calibracion (ver https://www.frontiersin.org/articles/10.3389/fnhum.2014.00443/full para mas detalle).
Por ultimo se explorara si las facetas y dominios que evalua el test se asocian de alguna manera con el genero de los participantes. 

# Parte A: Calibracion

## Parte 1: Exploracion

A.1) Los participantes, por el procedimiento en escalera deberian tener una precision (proporcion de respuestas correctas) del 0.72. Explorar la confianza promedio de cada participante en base al desempeño en la tarea de manera que ambas variables esten en un mismo grafico. 

A.2) Explorar la Calibracion mediante un histograma de la variable.

A.3) Eliminar del dataframe todas las variables que no comprendan algunas de las 25 facetas de personalidad. Sobre el dataframe filtrado graficar la correlacion entre todas las variables, observar si hay altos niveles de correlacion e informar que problemas podria traer esto para ajustar un modelo a los datos.

## Parte 2: Prediccion con facetas

Nuestro objetivo ahora es utilizar las facetas de la personalidad como variables predictoras de la Calibracion que tienen los sujetos. Dadas las correlaciones entre las distintas facetas vamos a utilizar un modelo de regresion lineal con el metodo de Elastic Net como metodo de regularizacion implementado mediante la funcion `glmnet` del paquete `glmnet`. 

Este metodo requiere dos hiper-parametros para ser ajustado: 

- El hiperparametro $\lambda$ donde $\lambda \in R_+$, regula el grado de penalizacion realizado por la regularizacion. 
- El hiperparametro $\alpha$ donde $\alpha \in [0,1]$, modula el tipo de regularizacion. Un valor de $\alpha = 0$ equivale a realizar una regularizacion de tipo *Ridge*, un valor de $\alpha = 1$ equivale a realizar una regularizacion de tipo *Lasso* y cualquier valor de $\alpha$ donde $0 < \alpha < 1$ resulta en una regularizacion por el metodo de Elastic Net. 

Para elegir estos parametros se utiliza un metodo de validacion cruazada, usualmente 10 fold cross-validation. En este caso por la poca cantidad de datos usaremos el metodo leave-one-out cross-validation (LOOCV).

A.4.1) Crear una funcion llamada `LOOCV.fun.glmnet` que implemente el metodo de LOOCV y calcule el la raiz cuadrada de la media de los errores cuadraticos (RMSE) como medida de error sobre los datos de testeo. Esta funcion tiene que poder permitirnos elegir el valor optimo de $\lambda$. 

A.4.2) Creaa un nuevo dataframe que contenga unicamente las variables predictoras del modelo junto con la variable de respuesta y guardalo con el nombre `d.regre.regul.facetas`.  

A.4.3) Crear una nueva funcion llamada `opt_alpha_lambda` que tome la funcion `LOOCV.fun.glmnet` y la use para optimizar un segundo parametro: $\alpha$ dando como resultado un dataframe con 3 columnas, dos columnas correspondiente al valor de $\alpha$ y $\lambda$ utilizado y una tercera correspondiente al puntaje de RMSE calculado segun LOOCV. 

A.4.4) Correr la funcion `opt_alpha_lambda` y guardar los resultados en un dataframe llamado `opt_alpha_lambda.df`

A.4.5) Calcular el indice que marca la combinacion de valores dentro de `opt_alpha_lambda.df` con el minimo valor de RMSE. 

A.4.6) Crear dos vectores llamados `lambda.optimo` y `alpha.optimo` correspondientes a los valores de $\lambda$ y $\alpha$ respectivamente que tienen con el valor de RMSE mas bajo. 

A.4.7) Correr el modelo de Elastic Net utilizando los parametros optimos guardados en los vectores `lambda.optimo` y `alpha.optimo` guardando el resultado en un objeto llamado `modelo.facetas`. 

A.4.8) Utilizar la funcion de la libreria `cv.glmnet()`, la cual te permite usar leave one out cross validation, y ver si te elige un lambda optimo si milar al que resulto de la funcion que creaste. Seria necesario darle a esta funcion alpha.optimo como parametro. Luego probar si los coeficentes del modelo correspondientes a ambos lambdas minimos son parecidos.

A.4.9) Interpretar los resultados

A.4.10) Graficar la relacion entre los hiperparametros y los valores de RMSE obtenidos segun LOOCV. 

## Parte 3: Prediccion con dominios

A.5) Armar un vector llamado `columnas_de_dominio` con los nombres de las columnas que contienen las variables de interes para el caso de los dominios.

A.6) Generar un vector llamado `mejor_subconjunto` que contenga las formulas (como strings) de todos los posibles modelos que pueden generarse a partir de los 5 dominios a utilizar como covariadas. Las formulas tienen que ser strings que contenga la variable `gender` como variable de respuesta y los dominions como variables predictoras. 
La cantidad total de modelos posibles de manera general es $\sum_{k = 1}^n\frac{n!}{k!(n-k)!}$ que para este caso nos da 31 por lo que debemos obtener un vector con longitud 31. 

A.7) Generar dos vectores llamados `formula_dominio_simple` y `formula_dominio_completa` que contenga las formulas con todos los predictores para los modelos univariados y para el modelo completo (multivariado), respectivamente. El vector `formula_dominio_simple` debe contener 5 modelos distintos, uno correspondiente a cada predictor y el vector `formula_dominio_completa` contiene un solo elemento que es el modelo con todas las covariadas agregadas.

A.8) Generar una funcion llamada `bootstrap_logistico` que dada una string denominada `formula_string`, correspondiente a la formula de un modelo de regresion logistica, calcule la media, el percentil 2.5 y el percentil 97.5 de la distribucion bootstrap para los parametros de la regresion logistica utilizando la funcion `quantile` para los percentiles y usando el metodo de Bootstrap no parametrico con 10 mil repeticiones.

A.9) Utilizando los vectores `formula_dominio_simple` y `formula_dominio_completa`, itere por cada una de las formulas y en cada caso utilice la funcion `bootstrap_logistico` para calcular los parametros relevantes de la distribucion bootstrap de los coeficientes $\beta$ para cada predictor en el caso del modelo simple (con un solo predictor) y en el caso del modelo completo (con todos los predictores). El resultado debe ser un dataframe donde cada fila corresponda a un coeficiente, indicado por una columna llamada `coeficiente`, identificado por una columna llamada `tipo_modelo` que indica si el coeficiente proviene de un modelo univariado o multivariado y con tres columnas correspondientes a la media, el percentil 2.5 y el percentil 97.5 correspondiente a cada coeficiente. Guardar el dataframe resultante en una variable llamada `bootstrap_dominio`.

A.10) Graficar los valores de los coeficientes con sus respectivos intervalos para cada predictor indicando con un color si la estimacion proviene de los modelos simples o del modelo completo e indicando con una linea punteada el valor de 0 en el grafico. 

A.11) Interpretar los resultados

A.12) Encontrar el modelo que tiene un mejor desempeño predictivo en el conjunto de testeo. Para eso utilizar el vector `mejor_subconjunto` para iterar por cada modelo evaluando su desempeño predictivo segun la media de los errores cuadraticos utilizando el procedimiento leave-one-out para elegir. Guardar el error cuadratrico 

A.13) Graficar el desempeño predictivo de cada uno de los modelos.

A.14) Interpretar los resultados

# Parte B: Genero

El objetivo ahora es utilizar las facetas y los dominios para predecir genero (entendido de manera reduccionista como binario: masculino y femenino). Siendo este un problema de clasificacion binario, vamos a utilizar usar una regresion logistica.

## Parte 3: Prediccion con facetas

B.1) Transformar la variable de genero para que en vez de ser 'Masculino' o 'Femenino' tenga un valor de 1 si es 'Masculino' y 0 si es 'Femenino'

B.2.1) Adaptar la funcion `LOOCV.fun.glmnet` de la Parte A para que utilice una regresion logsitica en lugar de una regresion lineal usando genero como variable de respuesta y las 25 facetas como predictores. Asi tambien, utilizar el accuracy en lugar del RMSE como medida a maximizar para encontrar el $\lambda$ optimo.

B.2.2) Creaa un nuevo dataframe que contenga unicamente las variables predictoras del modelo junto con la variable de respuesta y guardalo con el nombre `d.regre.regul.facetas`.  

B.2.3) Adaptar la funcion llamada `opt_alpha_lambda` para que optimice el $\alpha$ pero empleando una regresion logistica. 

B.2.4) Correr la funcion `opt_alpha_lambda` y guardar los resultados en un dataframe llamado `opt_alpha_lambda.df`

B.2.5) Calcular el indice que marca la combinacion de valores dentro de `opt_alpha_lambda.df` con el minimo valor de accuracy. 

B.2.6) Crear dos vectores llamados `lambda.optimo` y `alpha.optimo` correspondientes a los valores de $\lambda$ y $\alpha$ respectivamente que tienen con el valor de accuracy mas bajo. 

B.2.7) Correr el modelo de Elastic Net utilizando los parametros optimos guardados en los vectores `lambda.optimo` y `alpha.optimo` guardando el resultado en un objeto llamado `modelo.facetas`. 

B.2.8) Utilizar la funcion de la libreria `cv.glmnet()` y ver si te elige un lambda optimo si milar al que resulto de la funcion que creaste. Seria necesario darle a esta funcion alpha.optimo como parametro. Luego probar si los coeficentes del modelo correspondientes a ambos lambdas minimos son parecidos.

B.2.9) Interpretar los resultados

B.2.10) Graficar la relacion entre los hiperparametros y los valores de accuracy obtenidos segun LOOCV. 

## Parte 4: Prediccion con dominios

B.3) Tomar el vector llamado `mejor_subconjunto_genero` y modificar la palabra `overconfidence` por la palabra `gender` para generar todos los posibles modelos predictores del genero.

B.4) Generar dos vectores llamados `formula_simple_genero` y `formula_completa_genero` con la misma logica que en A.7 utilizando en este caso el vector `mejor_subconjunto_genero`. 

B.5) Modificar la funcion `bootstrap_lineal`, llamandola `bootstrap_logistico`, de manera que haga lo mismo que la funcion original pero empleando un modelo de regresion logistica.

B.6) Utilizando los vectores `formula_dominio_simple` y `formula_dominio_completa`, itere por cada una de las formulas y en cada caso utilice la funcion `bootstrap_logistico` para calcular los parametros relevantes de la distribucion bootstrap de los coeficientes $\beta$ para cada predictor en el caso del modelo simple (con un solo predictor) y en el caso del modelo completo (con todos los predictores). El resultado debe ser un dataframe donde cada fila corresponda a un coeficiente, indicado por una columna llamada `coeficiente`, identificado por una columna llamada `tipo_modelo` que indica si el coeficiente proviene de un modelo univariado o multivariado y con tres columnas correspondientes a la media, el percentil 2.5 y el percentil 97.5 correspondiente a cada coeficiente. Guardar el dataframe resultante en una variable llamada `bootstrap_dominio`.

B.7) Graficar los valores de los coeficientes con sus respectivos intervalos para cada predictor indicando con un color si la estimacion proviene de los modelos simples o del modelo completo e indicando con una linea punteada el valor de 0 en el grafico. 

B.8) Interpretar los resultados

B.9) Encontrar el modelo que tiene un mejor desempeño predictivo en el conjunto de testeo. Para eso utilizar el vector `mejor_subconjunto_genero` para iterar por cada modelo evaluando su desempeño predictivo segun la media de los errores cuadraticos utilizando el procedimiento leave-one-out para elegir. Guardar el error cuadratrico 

B.10) Graficar el desempeño predictivo de cada uno de los modelos.