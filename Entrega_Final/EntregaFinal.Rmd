---
title: "TrabajoFinal"
author: "Alejandro Ramos Usaj, Agostina Sacson y Iair Embon"
date: '2022-07-25'
output: html_document
---

```{r}
library(tidyverse)
```



Cargo los datos
```{r}
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())

# load the function to get the df list
# source(root$find_file("Entrega_Final/df_total_filtered.Rda")) ## me tira un error aca, no se poque lo voy a esta resolviendo

load("./df_total_filtered.Rda")
```

Lo exploro
```{r}
str(df_total)
```

Veo la cantidad de participantes
```{r}
print(length(unique(df_total$Participant)))
```


Exploro la variable de interes (Confianza)
```{r}
hist(df_total$confidence_key)
```

Convierto el df por trials en un df por participantes
```{r}
library(tidyverse)

d <- df_total %>%
  select(!c(RelyOn,
            Problems,
            ConfKey1,
            ConfKey2,
            ConfKey3,
            ConfKey4,
            discrimination_is_correct,
            confidence_key,
            trials,
            PointDifference,
            ReacTime_DiscTask,
            ReacTime_ConfTask)) %>%
  distinct(Participant,.keep_all = TRUE)
```

Exploro la otra variable de interes (metacognicion)
```{r}
plot(density(d$mc))
```

Exploro la confianza promedio de cada participante en base al desempeÃ±o en la tarea. Por el procedimiento en escalera deberian tener una precision (proporcion de respuestas correctas) del 0.72. 
```{r}
d %>%  ## no me estarian saliendo las leyendas, despues reviso
  select(ConfMean,PC,Participant) %>% 
  # normalizo el promedio de confianza por sujeto para que este en una escala similar a la del desempeno
  mutate(ConfMean = ConfMean/4, nr = row_number()) %>%
  arrange(ConfMean) %>%
  mutate(nr = row_number()) %>%
  ggplot(aes(x= nr)) +
  geom_point(aes(y=ConfMean), size = 2, color = "black") +
  geom_point(aes(y=PC), size = 2, color = "grey")+
  scale_x_continuous(expand = expansion(mult = c(0.01, 0.01))) +
  scale_y_continuous(expand = expansion(mult = c(0.01, 0.1))) +
  theme(axis.line = element_line(colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        plot.margin = margin(1, 1,1, 1, "cm"),
        legend.text =  element_text(size = 25),
        legend.position = c(0.7, 0.2),
        legend.background = element_blank(),
        legend.key = element_blank(),
        legend.title = element_blank(),
        panel.background = element_blank(),
        axis.text.x = element_text(size = 30),
        axis.text.y = element_text(size = 30),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())
```
Con esto se puede medir calibracion. Si la media de la confianza esta por encima de 0.72 entonces implica sobreconfianza, y si esta por debajo implica bajaconfianza. 

Agregamos una variable que va a decir si es overconfidence y underconfidence para cada participante. 
1 si es overconfidence.
```{r}
d <- d %>%
  mutate(ConfMean.norm = ConfMean/4, 
         overconfidence = ifelse(ConfMean.norm > 0.72, 1, 0))
# veo cuantos hay
d %>%
  summarise(n= sum(overconfidence))
# hay 81 participantes con alta confianza, lo que nos da 143 con baja confianza

```

Preproceso la varible genero
```{r}
d$gender <- ifelse(d$gender == "Masculino",1,0)
```


Corremos una regresion logistica para predecir underconfidence y overconfidence con los dominios de los rasgos disfuncionales de la personalidad
```{r}
model <- glm(overconfidence ~ DomainAntagonism + 
               DomainDetachment +
               DomainDisinhibition +
               DomainNegativeAffect + 
               DomainPsychoticism,
             family=binomial(link='logit'),
             data=d)
summary(model)
```

Corro otro modelo logistico pero esta vez controlo por edad y genero
```{r}
model2 <- glm(overconfidence ~ DomainAntagonism + 
               DomainDetachment +
               DomainDisinhibition +
               DomainNegativeAffect + 
               DomainPsychoticism +
               gender +
               age,
             family=binomial(link='logit'),
             data=d)
summary(model2)
```

#Regresion logistica usando metodos de regularizaciones

Corro una regresion logistica para predecir overconfidence usando tres metodos de regularizacion (ridge, lasso, elastic net).
Las primeras regresiones seran con las facetas, y las segundas seran con los dominios.

Por otro lado, es importante para estas regularizaciones, elegir un lambda adecuado, el cual se suele elegir mediante algun metodo de cross validation. Usualmente, en los trabajos que revisamos, usan 10 fold corss validation, aunque por la poca cantidad de datos usaremos leave one out cross validation (LOOCV). Para eso crearemos nuestra propia funcion de LOOCV

Funcion de LOOCV
```{r}
#### ME TIRA ERROR, ESTA FUNCION ESTA MAL, TODO EL MALDITO SISTEMA ESTA MAL

# creo una secuencua de posibles lambdas 
posibles_lambdas <- seq(0.01, 20 , length.out = 300)

for (j in 1:nrow(d.regre.regul.facetas)){
  
  # agrego una variable ID (participantes la saque para correr el modelo)
  d.regre.regul.facetas <- d.regre.regul.facetas %>% 
    mutate(id = row_number())
  
  # datos de entrenamiento (todos menos 1)
  train <- d.regre.regul.facetas %>%
    filter(id != d.regre.regul.facetas$id[j])
  
  # agarro el dato que quedo para el testeo
  test  <- anti_join(d.regre.regul.facetas, train, by = 'id')
  
  # Guardo las observaciones de overconfidence en entrenamiento y testeo(para entrenar el modelo y testearlo)
  y.train <- train$overconfidence
  y.test <- test$overconfidence
  
  # ahora les saco overconfidence (ya que no tiene que ir como predictor)
  train <- train %>%
    select(!overconfidence)
  
  test <- test %>%
    select(!overconfidence)
  
  # transformo en matrix
  train.m <- train %>% data.matrix()
  test.m <- test %>% data.matrix()
  
  # corro el modelo con los datos de entrenamiento
  modelo <- glmnet(train.m, y.train, family = "binomial",
                          alpha = 0, lambda = posibles_lambdas)
  
  # tomo los lambdas generados por el modelo (los mismo que le puse, pero tomo su orden)
  lambdas <- modelo$lambda
  
  # Creo la variable en la que voy a guardar el error para cada lambda
  error <- rep(NaN, length(nrow(d.regre.regul.facetas)))
  
  for (i in 1:length(lambdas)) {
    # obtengo el modelo que genera cada lambda
    lambda_i <- coef(modelo, s = lambdas[i])
    
    # hago prediccion sobre la data de testeo
    probabilities <- lambda_i %>% predict(new = test.m, type = "response")
    predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
    # Model accuracy
    caso.observado <- y.test
    error[i] <- mean(caso.prediccion == caso.observado) # revisar que sacar aca
  }

}

```


Cargo la libreria 
```{r}
library(glmnet)
```

#Para facetas

Primero trasnformo el dataframe a una matrix, como lo solicita la funcion necesaria para correr la reregresion usando regularizaciones. Ademas saco algunas variables que no van a ser necesarias.

```{r}

# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
  select(!c(Participant,
            DomainNegativeAffect,
            DomainDetachment,
            DomainAntagonism,
            DomainDisinhibition,
            DomainPsychoticism,
            PC,
            ConfMean,
            ConfSD,
            ReacTimeMean_DiscTask,
            ReacTimeSD_DiscTask,
            ReacTimeMean_ConfTask,
            ReacTimeSD_ConfTask,
            mc,
            ConfMean.norm))

d_mat <- d.regre.regul.facetas %>%
  data.matrix()
```

Ridge
```{r}
Ridge_Facetas <- glmnet(d_mat, d$overconfidence, family = "binomial",
                        alpha = 0, lambda = NULL)

plot(Ridge_Facetas)

```

Lasso
```{r}

```

Elastic net
```{r}

```



#Para Dominios


Ridge
```{r}

```





# Dominios


```{r}
domain_columns <- colnames(d)[str_detect(colnames(d), pattern = 'Domain')]
```



```{r}
sapply(
  1:5, function(x) combn(domain_columns, x, simplify = F) %>% 
                 lapply(function(y) str_flatten(y, ' + ')) %>% 
                 unlist()
       )  %>% unlist()
```




```{r}
single_domain_formula <- paste0(
  'overconfidence ~ ', domain_columns
)
```


```{r}
full_domain_formula <- as.formula(
  paste0(
    'overconfidence ~ ', str_flatten(domain_columns, ' + ')
         )
  )
```

