---
title: "TrabajoFinal"
author: "Alejandro Ramos Usaj, Agostina Sacson y Iair Embon"
date: '2022-07-25'
output: html_document
---

```{r}
library(tidyverse)
library(glmnet)
```

Cargo los datos
```{r}
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())

# load the function to get the df list
load("./df_total_filtered.Rda")
```

Saco la calibracion para cada participante, ver Fleming y Lau 2014
```{r}
df_calibracion <- df_total %>%
  group_by(Participant, confidence_key) %>%
  summarise(prop_correcta = mean(discrimination_is_correct)) %>%
  rename(ConfidenceKey = confidence_key)
  
df_calibracion.calculada <- df_total %>% 
  pivot_longer(cols = starts_with("ConfKey")) %>%
  distinct(Participant, name, .keep_all = TRUE) %>% 
  select(Participant, name, value) %>% 
  mutate(ConfidenceKey = as.integer(str_extract(name, "\\d"))) %>%
  left_join(df_calibracion) %>%
  drop_na() %>%
  mutate(ConfidenceKey = (ConfidenceKey+2)/6) %>%
  group_by(Participant) %>%
  mutate(Conf.norm = value / sum(value)) %>%
  mutate( preCalibracion = value*(prop_correcta - ConfidenceKey)**2) %>%
  summarise(Calibracion  = mean(preCalibracion))
```

Convierto el data frame por trials en un data frame por participantes
```{r}
d <- df_total %>%
  select(!c(RelyOn,
            Problems,
            ConfKey1,
            ConfKey2,
            ConfKey3,
            ConfKey4,
            discrimination_is_correct,
            confidence_key,
            trials,
            PointDifference,
            ReacTime_DiscTask,
            ReacTime_ConfTask)) %>%
  distinct(Participant,.keep_all = TRUE)

# le agrego la variable calibracion
d <- d %>%
  mutate(Calibracion = df_calibracion.calculada$Calibracion)
```

Parte A: CALIBRACION

A.1) Explorar la confianza promedio de cada participante en base al desempeÃ±o en la tarea. Por el procedimiento en escalera deberian tener una precision (proporcion de respuestas correctas) del 0.72. Que ambas variables esten en un mismo grafico.
```{r}
d %>%  ## no me estarian saliendo las leyendas, despues reviso
  select(ConfMean,PC,Participant) %>% 
  # normalizo el promedio de confianza por sujeto para que este en una escala similar a la del desempeno
  mutate(ConfMean = ConfMean/4, nr = row_number()) %>%
  arrange(ConfMean) %>%
  mutate(nr = row_number()) %>%
  ggplot(aes(x= nr)) +
  geom_point(aes(y=ConfMean), size = 2, color = "black") +
  geom_point(aes(y=PC), size = 2, color = "grey")+
  scale_x_continuous(expand = expansion(mult = c(0.01, 0.01))) +
  scale_y_continuous(expand = expansion(mult = c(0.01, 0.1))) +
  theme(axis.line = element_line(colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        plot.margin = margin(1, 1,1, 1, "cm"),
        legend.text =  element_text(size = 25),
        legend.position = c(0.7, 0.2),
        legend.background = element_blank(),
        legend.key = element_blank(),
        legend.title = element_blank(),
        panel.background = element_blank(),
        axis.text.x = element_text(size = 30),
        axis.text.y = element_text(size = 30),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())
```

A.2) Explorar Calibracion mediante un histograma de la variable.
```{r}
hist(d$Calibracion)
```

A.3) Corre una regresion lineal para predecir calibracion con los dominios de los rasgos disfuncionales de la personalidad. Mira los resultados con summary()
```{r}
model <- lm(Calibracion ~ DomainAntagonism + 
               DomainDetachment +
               DomainDisinhibition +
               DomainNegativeAffect + 
               DomainPsychoticism,
             data=d)
summary(model)
```

A.4) Corre otro modelo lineal pero esta vez controla por edad y genero, metiendolas en el modelo. Observar los resultados con summary(). 
```{r}
model2 <- lm(Calibracion ~ DomainAntagonism + 
               DomainDetachment +
               DomainDisinhibition +
               DomainNegativeAffect + 
               DomainPsychoticism +
               gender +
               age,
             data=d)
summary(model2)
```

A.5) Observa si hay altos niveles de correlacion entre varibles.

```{r}
# saco las variables que no necesito
d.cor <- d %>%
  select(!c(DomainNegativeAffect,
            DomainDetachment,
            DomainAntagonism,
            DomainDisinhibition,
            DomainPsychoticism,
            PC,
            ConfMean,
            ConfSD,
            ReacTimeMean_DiscTask,
            ReacTimeSD_DiscTask,
            ReacTimeMean_ConfTask,
            ReacTimeSD_ConfTask,
            mc,
            gender,
            Participant,
            age,
            Calibracion))


library(corrplot)

# ploteo la correlacion
corrplot(cor(d.cor), type="upper", method = "ellipse", tl.srt=45)

# me fijo cuantas correlaciones mayores a .6 hay
sum(cor(d.cor) > 0.6)

```


A.6) Regresion lineal usando metodos de regularizaciones:


Corre una regresion lineal para predecir calibracion usando un metodo de regularizacion para predecir facetas.

A.6.1)
Por otro lado, es importante para estas regularizaciones, elegir un lambda adecuado, el cual se suele elegir mediante algun metodo de cross validation. Usualmente, en los trabajos que revisamos, usan 10 fold corss validation, aunque por la poca cantidad de datos usa leave one out cross validation (LOOCV). Para eso crea tu propia funcion de LOOCV. Usa el root mean squared errors como medida de error. 
Crea una funcion para realizar un LOOCV y elegir asi el valor de lambda optimo.

```{r}
#### 

LOOCV.fun.glmnet <- function(df, alpha.dado){
  ### Primero creo una secuencua de posibles lambdas, desde un modelo desechable
  
  # Guardo las observaciones de genero
  y <- df$Calibracion

  # ahora les saco genero y Participant (ya que no tienen que ir como predictores)
  df.lambda <- df %>% select(!c(Calibracion,Participant))

  # transformo en matrix
  df.lambda.m <- df.lambda %>% data.matrix()

  # Corro el modelo y obtengo el lambda
  modelo.lambda <- glmnet(df.lambda.m, y,
                            alpha = alpha.dado)
  posibles_lambdas <- modelo.lambda$lambda
  
  # creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
  matriz.errores <- matrix(data=NA,nrow= nrow(df),
                           ncol= length(posibles_lambdas))
  
  for (j in 1:nrow(df)){
    # datos de entrenamiento (todos menos 1)
    train <- df %>%
      filter(Participant != df$Participant[j])
    
    # agarro el dato que quedo para el testeo
    test  <- anti_join(df, train, by = 'Participant')
    
    # Guardo las observaciones de genero en entrenamiento y testeo (para entrenar el modelo y testearlo)
    y.train <- train$Calibracion
    y.test <- test$Calibracion
    
    # ahora les saco genero y Participant (ya que no tienen que ir como predictores)
    train <- train %>% select(!c(Calibracion,Participant))
    test <- test %>% select(!c(Calibracion,Participant))
    
    # transformo en matrix
    train.m <- train %>% data.matrix()
    test.m <- test %>% data.matrix()
    
    # corro el modelo con los datos de entrenamiento
    modelo <- glmnet(train.m, y.train,
                     alpha = alpha.dado, 
                     lambda = posibles_lambdas)
    
    # hago prediccion sobre la data de testeo
    matriz.errores[j,] <- modelo %>% predict(newx = test.m, type = "response")
  }
  
  # saco los root mean squared errors para cada lambda
  lambda.RMSE <- sqrt(((colSums(matriz.errores))**2)/nrow(df))
  
  list_return <- list("lambda.RMSE" = lambda.RMSE,
                      "lambdas" = posibles_lambdas)
  
  return(list_return)
  }

```

A.6.2) Preprocesa el dataframe en base a lo que necesita la funcion glmnet(). 

Primero saca las variables que no seran predictoras en el modelo.

```{r}

# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
  select(!c(DomainNegativeAffect,
            DomainDetachment,
            DomainAntagonism,
            DomainDisinhibition,
            DomainPsychoticism,
            PC,
            ConfMean,
            ConfSD,
            ReacTimeMean_DiscTask,
            ReacTimeSD_DiscTask,
            ReacTimeMean_ConfTask,
            ReacTimeSD_ConfTask,
            mc,
            gender))
```

A.6.3)
Crea una funcion que tome la funcion que elige el lambda optimo y que lo use para optimizar un segundo parametro: alpha. Este parametro es el que controla el tipo de regularizacion a optimizar.

```{r}
opt_alpha_lambda <- function(df){
  
  # Creo los vectores que van a contener todos los lambdas, alphas y sus respectivos RMSE
  alphas.usados <- c()
  lambdas.usados <- c()
  RMSE <- c()
  
  # creo los alphas que vamos a usar
  muchos.alphas <- seq(0,1, by = 0.1)
  
  # itero por varios alphas
  for (i in 1:length(muchos.alphas)) {
    alpha.dado <- muchos.alphas[i]
    
    # Hago LOOCV para elegir varios lambdas
    lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
    
    RMSE <- c(RMSE, lambdaOptimo_facetas$lambda.RMSE)
    alphas.usados <- c(alphas.usados, rep(alpha.dado,length(lambdaOptimo_facetas$lambda.RMSE)))
    lambdas.usados <- c(lambdas.usados,lambdaOptimo_facetas$lambdas)
  }
  
  df_alp_lambd_RMSE <- data.frame(alpha = alphas.usados,
                                  lambda = lambdas.usados,
                                  RMSE = RMSE)
    
  return(df_alp_lambd_RMSE)
}

opt_alpha_lambda.df <- opt_alpha_lambda(d.regre.regul.facetas)

# tomo el lambda que tiene el menor error
index.opt.param <- which.min(opt_alpha_lambda.df$RMSE)
  
# Corro el modelo con el alpha optimo y el lambda que minimiza el error
lambda.optimo <- opt_alpha_lambda.df$lambda[index.opt.param]
alpha.optimo <- opt_alpha_lambda.df$alpha[index.opt.param]  

### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$Calibracion
  
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(Calibracion,Participant))
  
# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()

# Corro el modelo y obtengo el lambda
modelo.facetas <- glmnet(d.regre.regul.facetas.prepro.m, y,
                          alpha = alpha.optimo, lambda = lambda.optimo)

# me fijo el lambda optimo que me elije el modelo por si solo usando funciones de la libreria, para alpha = alpha.optimo
modelo.facetas2 <- glmnet(d.regre.regul.facetas.prepro.m, y,
                          alpha = alpha.optimo)
coef(modelo.facetas2)
set.seed(1010)
cvfit <- cv.glmnet(d.regre.regul.facetas.prepro.m,y, type.measure = "mse", nfolds = nrow(d.regre.regul.facetas))
cvfit$lambda.min
coef(cvfit, s = "lambda.min")
# veo que son parecidos al seleccionado con la funcion que cree
```

A.6.4) Interpretar los resultados

# Esto fue oara las facetas, ahora vamos a investigar los Dominios

A.7) Armar un vector llamado `columnas_de_dominio` con los nombres de las columnas que contienen las variables de interes para el caso de los dominios.

```{r}
columnas_de_dominio <- colnames(d)[str_detect(colnames(d), pattern = 'Domain')]
```

A.8) Generar un vector llamado `mejor_subconjunto` que contenga las formulas (como strings) de todos los posibles modelos que pueden generarse a partir de los 5 dominios a utilizar como covariadas. Las formulas tienen que ser strings que contenga la variable `gender` como variable de respuesta y los dominions como variables predictoras. 
La cantidad total de modelos posibles de manera general es $\sum_{k = 1}^n\frac{n!}{k!(n-k)!}$ que para este caso nos da 31 por lo que debemos obtener un vector con longitud 31. 

```{r}
mejor_subconjunto <- sapply(
  1:5, function(x) combn(columnas_de_dominio, x, simplify = F) %>% 
                 lapply(function(y) str_flatten(y, ' + ')) %>% 
                 unlist()
       )  %>% unlist() %>%
  sapply(
    function(x) paste0('Calibracion ~ ', x) 
  ) %>% unname()
```

A.9) Generar dos vectores llamados `formula_dominio_simple` y `formula_dominio_completa` que contenga las formulas con todos los predictores para los modelos univariados y para el modelo completo (multivariado), respectivamente. El vector `formula_dominio_simple` debe contener 5 modelos distintos, uno correspondiente a cada predictor y el vector `formula_dominio_completa` contiene un solo elemento que es el modelo con todas las covariadas agregadas. 

```{r}
formula_dominio_simple <- mejor_subconjunto[1:5]
formula_dominio_completa <- mejor_subconjunto[length(mejor_subconjunto)]
```

A.10) Generar una funcion llamada `bootstrap_logistico` que dada una string denominada `formula_string`, correspondiente a la formula de un modelo de regresion logistica, calcule la media, el percentil 2.5 y el percentil 97.5 de la distribucion bootstrap para los parametros de la regresion logistica utilizando la funcion `quantile` para los percentiles y usando el metodo de Bootstrap no parametrico con 10 mil repeticiones.

```{r}
bootstrap_lineal <- function(formula_string) {
  replicate(10000,
  lm(as.formula(formula_string),
      data = slice_sample(d, n =nrow(d), replace = T)
      )$coeff
  ) %>%
  apply(
    1, 
    FUN = function(x.row) c(media = mean(x.row), 
                            quantile(x.row, c(0.025,0.975))
                            )
  )
}
```

A.11) Utilizando los vectores `formula_dominio_simple` y `formula_dominio_completa`, itere por cada una de las formulas y en cada caso utilice la funcion `bootstrap_logistico` para calcular los parametros relevantes de la distribucion bootstrap de los coeficientes $\beta$ para cada predictor en el caso del modelo simple (con un solo predictor) y en el caso del modelo completo (con todos los predictores). El resultado debe ser un dataframe donde cada fila corresponda a un coeficiente, indicado por una columna llamada `coeficiente`, identificado por una columna llamada `tipo_modelo` que indica si el coeficiente proviene de un modelo univariado o multivariado y con tres columnas correspondientes a la media, el percentil 2.5 y el percentil 97.5 correspondiente a cada coeficiente. Guardar el dataframe resultante en una variable llamada `bootstrap_dominio`.

```{r}
set.seed(1234)
bootstrap_dominio <- sapply(
  c(formula_dominio_simple,formula_dominio_completa),
  bootstrap_lineal 
  ) %>% lapply(as.data.frame) %>% bind_rows() %>%
  mutate(
    tipo_modelo = rep(
      c('simple','completo'), c(3*5,3)
      )
         ) %>% 
  rownames_to_column(var = 'tipo_medicion') %>%
  mutate(tipo_medicion = str_replace(tipo_medicion, 'media\\d|\\...\\d+','')) %>% 
  pivot_longer(!starts_with('tipo'), names_to = 'coeficiente', values_to = 'estimacion') %>%
  drop_na() %>%
  filter(coeficiente != '(Intercept)') %>%
  pivot_wider(names_from = tipo_medicion, values_from = estimacion)
```

A.12) Graficar los valores de los coeficientes con sus respectivos intervalos para cada predictor indicando con un color si la estimacion proviene de los modelos simples o del modelo completo e indicando con una linea punteada el valor de 0 en el grafico. 

```{r}
bootstrap_dominio %>%
  ggplot(
    aes(x = coeficiente, y = media, color = tipo_modelo, ymin = `2.5%`, ymax = `97.5%`)
  ) +
  geom_point(
    position = position_dodge(.8)
  ) +
  geom_errorbar(
    width = .2,
    position = position_dodge(.8)
  ) +
  geom_hline(yintercept = 0) +
  coord_flip() +
  ylab('Estimacion') + xlab('Coeficientes') +
  scale_color_discrete('Tipo de Modelo', labels = c('Multiple', 'Simple'))
```

A.13) Interpretar los resultados

> En todos los casos los intervalos de confianza del 95% de las variables predictoras, ya sea para el modelo univariado o multivariado, alcanzan el valor del 0 lo cual indica que no podemos concluir que la pendiente de alguna de las covariadas sea distinta de 0 dados los datos. 

A.14) Encontrar el modelo que tiene un mejor desempeÃ±o predictivo en el conjunto de testeo. Para eso utilizar el vector `mejor_subconjunto` para iterar por cada modelo evaluando su desempeÃ±o predictivo segun la media de los errores cuadraticos utilizando el procedimiento leave-one-out para elegir. Guardar el error cuadratrico 

```{r}
predicciones_mejor_subconjunto <- pmap(
  expand.grid(1:nrow(d), mejor_subconjunto) %>% mutate(Var2 = as.character(Var2)),
  ~ lm(
      as.formula(.y), data = d, subset = -.x
    ) %>% predict(d[.x, ], type = 'response') - d[.x, 'Calibracion']
) %>%
  unlist() %>% mutate(expand.grid(1:nrow(d), mejor_subconjunto), pred = .,
                      error = pred - d[Var1, 'Calibracion'],
                      error_cuadratico = error^2) %>%
  rename(Modelo = Var2)
```

A.15) Graficar el desempeÃ±o predictivo de cada uno de los modelos. 

```{r}
ggplot(predicciones_mejor_subconjunto,
  aes(x = Modelo, y = error_cuadratico)
) +
  geom_boxplot() +
  coord_flip() +
  theme(axis.text.y = element_text(size = 5))
```

A.16) Interpretar los resultados

> No se observan diferencias en la capacidad predictiva de los distintos modelos sobre el conjunto de testeo segun el metodo de validacion cruzada leave-one-out. Por lo tanto dada la varianza en los resultados no seria prudente elegir el valor que minimiza la media de los errores cuadraticos empiricos considerando que no habria suficiente evidencia para concluir que los dominios de personalidad predicen la calibracion. 


Parte B: Ahora vamos a utilizar las facetas y los dominios para predecir genero (entendido de manera reduccionista como binario: masculino y femenino). Para eso, uno de los posibles engfoques adecuados seria usar una regresion logistica. 

Preproceso la varible genero
```{r}
d$gender <- ifelse(d$gender == "Masculino",1,0)
```

# Regresion logistica usando metodos de regularizaciones

B.1) Corre una regresion logistica para predecir genero usando metodos de regularizacion para predecir facetas.
Para esto, adapta la funcion que creaste para LOOCV en la parte A, pero ahora para que funcione con una regresion logistica. Utiliza el accuracy como medida a maximizar para encontrar el lambda optimo.

```{r}
#### 

LOOCV.fun.glmnet <- function(df, alpha.dado){
  ### Primero creo una secuencua de posibles lambdas, desde un modelo desechable
  
  # Guardo las observaciones de genero
  y <- df$gender

  # ahora les saco genero y Participant (ya que no tienen que ir como predictores)
  df.lambda <- df %>% select(!c(gender,Participant))

  # transformo en matrix
  df.lambda.m <- df.lambda %>% data.matrix()

  # Corro el modelo y obtengo el lambda
  modelo.lambda <- glmnet(df.lambda.m, y , family = "binomial",
                            alpha = alpha.dado)
  posibles_lambdas <- modelo.lambda$lambda
  
  # creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
  matriz.errores <- matrix(data=NA,nrow= nrow(df),
                           ncol= length(posibles_lambdas))
  
  for (j in 1:nrow(df)){
    # datos de entrenamiento (todos menos 1)
    train <- df %>%
      filter(Participant != df$Participant[j])
    
    # agarro el dato que quedo para el testeo
    test  <- anti_join(df, train, by = 'Participant')
    
    # Guardo las observaciones de genero en entrenamiento y testeo (para entrenar el modelo y testearlo)
    y.train <- train$gender
    y.test <- test$gender
    
    # ahora les saco genero y Participant (ya que no tienen que ir como predictores)
    train <- train %>% select(!c(gender,Participant))
    test <- test %>% select(!c(gender,Participant))
    
    # transformo en matrix
    train.m <- train %>% data.matrix()
    test.m <- test %>% data.matrix()
    
    # corro el modelo con los datos de entrenamiento
    modelo <- glmnet(train.m, y.train, family = "binomial",
                            alpha = alpha.dado, lambda = posibles_lambdas)
    
    # hago prediccion sobre la data de testeo
    probabilities <- modelo %>% predict(newx = test.m, type = "response")
    predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
    # Model accuracy
    matriz.errores[j,] <- predicted.classes == y.test
  }
  
  list_return <- list("matriz.errores" = matriz.errores,
                      "lambdas" = posibles_lambdas)
  
  return(list_return)
}

```

B.2) Preprocesa el dataframe en base a lo que necesita la funcion glmnet(). 

Primero saca las variables que no seran predictoras en el modelo.
```{r}
# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
  select(!c(DomainNegativeAffect,
            DomainDetachment,
            DomainAntagonism,
            DomainDisinhibition,
            DomainPsychoticism,
            PC,
            ConfMean,
            ConfSD,
            ReacTimeMean_DiscTask,
            ReacTimeSD_DiscTask,
            ReacTimeMean_ConfTask,
            ReacTimeSD_ConfTask,
            mc))

```

B.3) Adapta tu funcion de la parte A para que optimice el alpha, pero ahora para una regresion logistica.
```{r}
opt_alpha_lambda <- function(df){
  
  # Creo los vectores que van a contener todos los lambdas, alphas y sus respectivos accuracy
  alphas.usados <- c()
  lambdas.usados <- c()
  accuracy <- c()
  
  # creo los alphas que vamos a usar
  muchos.alphas <- seq(0,1, by = 0.1)
  
  # itero por varios alphas
  for (i in 1:length(muchos.alphas)) {
    alpha.dado <- muchos.alphas[i]
    
    # Hago LOOCV para elegir varios lambdas
    lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
    
    matriz.errores <- lambdaOptimo_facetas$matriz.errores
    # saco la proporcion de aciertos
    accuracy <- c(accuracy, colMeans(matriz.errores))
    lambdas.usados <- c(lambdas.usados,lambdaOptimo_facetas$lambdas)
    alphas.usados <- c(alphas.usados, rep(alpha.dado, length(lambdaOptimo_facetas$lambdas)))
  }
  
  df_alp_lambd_accuracy <- data.frame(alpha = alphas.usados,
                                  lambda = lambdas.usados,
                                  accuracy = accuracy)
    
  return(df_alp_lambd_accuracy)
}

opt_alpha_lambda.df <- opt_alpha_lambda(d.regre.regul.facetas)

# tomo el lambda que tiene el menor error
index.opt.param <- which.min(opt_alpha_lambda.df$accuracy)
  
# Corro el modelo con el alpha optimo y el lambda que minimiza el error
lambda.optimo <- opt_alpha_lambda.df$lambda[index.opt.param]
alpha.optimo <- opt_alpha_lambda.df$alpha[index.opt.param]  

### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$gender
  
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(gender,Participant))
  
# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()

# Corro el modelo y obtengo el lambda
modelo.facetas <- glmnet(d.regre.regul.facetas.prepro.m, y,
                          family = "binomial",
                          alpha = alpha.optimo, lambda = lambda.optimo)

coef(modelo.facetas)
# me fijo el lambda optimo que me elije el modelo por si solo usando funciones de la libreria, para alpha = 1
modelo.facetas2 <- glmnet(d.regre.regul.facetas.prepro.m, y,
                           family = "binomial",
                           alpha = alpha.optimo)
coef(modelo.facetas2)
set.seed(1010)
cvfit <- cv.glmnet(d.regre.regul.facetas.prepro.m,y, type.measure = "auc", nfolds = nrow(d.regre.regul.facetas))
cvfit$lambda.min
coef(cvfit, s = "lambda.min")
# son parecidas
```

B.4) Interpretar los resultados.



# Ahora vamos a hacer lo mismo con los Dominios. Queremos predecir genero.

B.5) Generar un nuevo vector llamado `mejor_subconjunto_genero` de la misma manera que en el ejercicio [IGUAL QUE EN EL EJERCICIO CON LA REGRESION LINEAL] modificando unicamente la variable de respuesta por la variable `gender`. 

```{r}
mejor_subconjunto_genero <- sapply(
  1:5, function(x) combn(columnas_de_dominio, x, simplify = F) %>% 
                 lapply(function(y) str_flatten(y, ' + ')) %>% 
                 unlist()
       )  %>% unlist() %>%
  sapply(
    function(x) paste0('gender ~ ', x) 
  ) %>% unname()
```

B.6) Generar dos vectores llamados `formula_simple_genero` y `formula_completa_genero` con la misma logica que en [EL EJERCICIO CON LA LINEAL] utilizando en este caso el vector `mejor_subconjunto_genero`. 

```{r}
formula_simple_genero <- mejor_subconjunto_genero[1:5]
formula_completa_genero <- mejor_subconjunto_genero[length(mejor_subconjunto)]
```

B.7) Modificar la funcion `bootstrap_lineal`, llamandola `bootstrap_logistico`, de manera que haga lo mismo que la funcion original pero empleando un modelo de regresion logistica.

```{r}
bootstrap_logistico <- function(formula_string) {
  replicate(10000,
  glm(as.formula(formula_string), family = binomial(link = 'logit'),
      data = slice_sample(d, n =nrow(d), replace = T)
      )$coeff
  ) %>%
  apply(
    1, 
    FUN = function(x.row) c(media = mean(x.row), 
                            quantile(x.row, c(0.025,0.975))
                            )
  )
}
```

B.8) Evalue el funcionamiento de `bootstrap_logistico` empleando alguna formula que use como variable de respuesta el genero. 

```{r}
bootstrap_logistico('gender ~ age')
```
B.9) Utilizando los vectores `formula_dominio_simple` y `formula_dominio_completa`, itere por cada una de las formulas y en cada caso utilice la funcion `bootstrap_logistico` para calcular los parametros relevantes de la distribucion bootstrap de los coeficientes $\beta$ para cada predictor en el caso del modelo simple (con un solo predictor) y en el caso del modelo completo (con todos los predictores). El resultado debe ser un dataframe donde cada fila corresponda a un coeficiente, indicado por una columna llamada `coeficiente`, identificado por una columna llamada `tipo_modelo` que indica si el coeficiente proviene de un modelo univariado o multivariado y con tres columnas correspondientes a la media, el percentil 2.5 y el percentil 97.5 correspondiente a cada coeficiente. Guardar el dataframe resultante en una variable llamada `bootstrap_dominio`.

```{r}
set.seed(1234)
bootstrap_dominio <- sapply(
  c(formula_dominio_simple,formula_dominio_completa),
  bootstrap_logistico 
  ) %>% lapply(as.data.frame) %>% bind_rows() %>%
  mutate(
    tipo_modelo = rep(
      c('simple','completo'), c(3*5,3)
      )
         ) %>% 
  rownames_to_column(var = 'tipo_medicion') %>%
  mutate(tipo_medicion = str_replace(tipo_medicion, 'media\\d|\\...\\d+','')) %>% 
  pivot_longer(!starts_with('tipo'), names_to = 'coeficiente', values_to = 'estimacion') %>%
  drop_na() %>%
  filter(coeficiente != '(Intercept)') %>%
  pivot_wider(names_from = tipo_medicion, values_from = estimacion)
```

B.10)
Graficar los valores de los coeficientes con sus respectivos intervalos para cada predictor indicando con un color si la estimacion proviene de los modelos simples o del modelo completo e indicando con una linea punteada el valor de 0 en el grafico. 

```{r}
bootstrap_dominio %>%
  ggplot(
    aes(x = coeficiente, y = media, color = tipo_modelo, ymin = `2.5%`, ymax = `97.5%`)
  ) +
  geom_point(
    position = position_dodge(.8)
  ) +
  geom_errorbar(
    width = .2,
    position = position_dodge(.8)
  ) +
  geom_hline(yintercept = 0) +
  coord_flip() +
  ylab('Estimacion') + xlab('Coeficientes') +
  scale_color_discrete('Tipo de Modelo', labels = c('Multiple', 'Simple'))
```

B.11)
Interpretar los resultados

B.12)
Evaluar un ajuste polinomial para la regresion logistica generando una grilla de posibles valores para el grado del polinomio que vaya de 1 a 15 (con intervalos de 1) y ajustar el modelo usando la funcion `poly`. Para cada grado posible del polinomio utilizar un procedimiento leave-one-out para calcular el accuracy y elegir asi el grado optimo del polinomio a utilizar.

```{r, warning=FALSE}
grilla_grado <- expand.grid(indice = 1:nrow(d), grado = 1:15)

spam <- grilla_grado %>% mutate(
  probabilidad = grilla_grado %>% 
    pmap(
      ~ glm(overconfidence ~ poly(DomainDisinhibition, .y), family = binomial(link = 'logit'),
            data = d[-.x, ]
            ) %>% 
        predict(d[.x, ], type = 'response')
      ) %>% 
    unlist(),
  prediccion = ifelse(probabilidad > 0.5, 1, 0),
  acierto = prediccion == d[indice, 'overconfidence']
  ) %>% group_by(grado) %>% summarise(accuracy = mean(acierto))

spam %>%
  ggplot(
    aes(x = grado, y = accuracy)
  ) + geom_smooth(span = 0.3) +
  geom_hline(
    yintercept = d %>% count(overconfidence) %>% mutate(n = n/sum(n)) %>% pull(n) %>% max(),
    linetype = 'dashed'
  )
```

B.13)
Utilizando el vector `mejor_subconjunto` emplear el procedimiento leave-one-out para elegir el modelo con mejor capacidad predictiva de todos los posibles.

```{r}
predicciones_mejor_subconjunto <- pmap(
  expand.grid(1:nrow(d), mejor_subconjunto) %>% mutate(Var2 = as.character(Var2)),
  ~ glm(
      as.formula(.y), family = binomial(link = 'logit'), data = d, subset = -.x
    ) %>% predict(d[.x, ], type = 'response')
) %>%
  unlist()

resultado_mejor_subconjunto <- expand.grid(1:nrow(d), mejor_subconjunto) %>%
  mutate(pred = predicciones_mejor_subconjunto,
         respuesta = ifelse(pred > 0.5, 1, 0),
         acierto = as.numeric(respuesta == d[Var1, 'overconfidence'])) %>%
  ggplot(
  aes(x = Var2, y = acierto)
) +
  stat_summary(geom = 'pointrange') +
  coord_flip() +
  theme(axis.text.y = element_text(size = 5))
```
B.14)
Representar en una tabla sus estimaciones puntuales con un intervalo de confianza del 95% construido a partir de 10000 muestras bootstrap no parametricas. 

