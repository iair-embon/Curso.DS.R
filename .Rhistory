#vari <- 1/lambda**2
#p_40 <- 1-exp(-lambda*40)
#### 13
lambda <- 0.03
require(dplyr)
p_40_sombrero <- df %>%
filter(f <= 40) %>%
nrow()/length(df$f)
lambda_est <- 1/mean(df$f)
p_40_rulo <- pexp(40, lambda_est)
# creo una funcion que saque el ECME para el estimador sombrero
ECME_sombrero <- function(n){
Nrep <- 1000
muchos_p_40_sombrero <- rep(NaN,Nrep)
for (i in 1:Nrep) {
muchas_exponenciales <- rexp(n, 0.03)
p_sombrero <- length(muchas_exponenciales[muchas_exponenciales <= 40])/
length(muchas_exponenciales)
muchos_p_40_sombrero[i] <- p_sombrero
}
p_40 <- 1-exp(-lambda*40)
ECME_sombrero <- sum((muchos_p_40_sombrero-  p_40)**2) /
length(muchos_p_40_sombrero)
return(ECME_sombrero)
}
# creo una funcion que saque el ECME para el estimador rulo
ECME_rulo <- function(n){
Nrep <- 1000
muchos_p_40_rulo <- rep(NaN,Nrep)
for (i in 1:Nrep) {
muchas_exponenciales <- rexp(n, 0.03)
lambda_est <- 1/mean(muchas_exponenciales)
p_rulo <- pexp(40, lambda_est)
muchos_p_40_rulo[i] <- p_rulo
}
p_40 <- 1-exp(-lambda*40)
ECME_rulo <- sum((muchos_p_40_rulo -  p_40)**2) /
length(muchos_p_40_rulo)
return(ECME_rulo)
}
# pruebo la funcion con diferentes ns
# n50
ECME_sombrero_n50 <- ECME_sombrero(n=50)
ECME_rulo_n50 <- ECME_rulo(n=50)
# n150
ECME_sombrero_n150 <- ECME_sombrero(n=150)
ECME_rulo_n150 <- ECME_rulo(n=150)
# n200
ECME_sombrero_n200 <- ECME_sombrero(n=200)
ECME_rulo_n200 <- ECME_rulo(n=200)
# n500
ECME_sombrero_n500 <- ECME_sombrero(n=500)
ECME_rulo_n500 <- ECME_rulo(n=500)
df.ECME <- data.frame(estimador = c("rulo","sombrero"),
n50 = c(ECME_rulo_n50,ECME_sombrero_n50),
n150= c(ECME_rulo_n150,ECME_sombrero_n150),
n200= c(ECME_rulo_n200,ECME_sombrero_n200),
n500= c(ECME_rulo_n500,ECME_sombrero_n500))
print(df.ECME)
# Se prefiere el estimador rulo, ya que en cada estimacion
# tuvo un menor error cuadratico medio empirico.
?elseif
?ifelse
sample(1:6,1, replace = T)
sample(1:6,1, replace = T)
sample(1:6,1, replace = T)
sample(1:6,1, replace = T)
sample(1:6,1, replace = T)
sample(1:6,1, replace = T)
sample(1:6,1, replace = T)
albun <- 1:6
albun
albun_en_proceso <- rep(NaN,6)
albun_en_proceso <- rep(NaN, length(albun_completo))
albun_completo <- 1:6
albun_en_proceso <- rep(NaN, length(albun_completo))
fig <- sample(1:6,1, replace = T)
!(fig %IN% albun_en_proceso)
!(fig %in% albun_en_proceso)
albun_completo <- 1:6
albun_en_proceso <- rep(NaN, length(albun_completo))
while (albun_completo != albun_en_proceso) {
fig <- sample(1:6,1, replace = T)
if(!(fig %in% albun_en_proceso)){
albun_en_proceso[fig] <- fig
}
}
albun_en_proceso
albun_completo
albun_completo != albun_en_proceso
albun_completo != albun_en_proceso
albun_completo != albun_en_proceso
albun_completo != albun_en_proceso
albun_en_proceso <- rep(0, length(albun_completo))
albun_completo != albun_en_proceso
albun_completo <- 1:6
albun_en_proceso <- rep(0, length(albun_completo))
while (sum(albun_completo != albun_en_proceso) != 0) {
fig <- sample(1:6,1, replace = T)
if(!(fig %in% albun_en_proceso)){
albun_en_proceso[fig] <- fig
}
}
albun_en_proceso
albun_completo <- 1:6
albun_en_proceso <- rep(0, length(albun_completo))
compra_paquete <- 1
while (sum(albun_completo != albun_en_proceso) != 0) {
fig <- sample(1:6,1, replace = T)
if(!(fig %in% albun_en_proceso)){
albun_en_proceso[fig] <- fig
}
compra_paquete <- compra_paquete + 1
}
compra_paquete
cuantasFigus <- function(figusTotal){
albun_completo <- 1:figusTotal
albun_en_proceso <- rep(0, length(albun_completo))
compra_paquete <- 1
while (sum(albun_completo != albun_en_proceso) != 0) {
fig <- sample(1:figusTotal,1, replace = T)
if(!(fig %in% albun_en_proceso)){
albun_en_proceso[fig] <- fig
}
compra_paquete <- compra_paquete + 1
}
}
cuantasFigus(6)
cuantasFigus <- function(figusTotal){
albun_completo <- 1:figusTotal
albun_en_proceso <- rep(0, length(albun_completo))
compra_paquete <- 1
while (sum(albun_completo != albun_en_proceso) != 0) {
fig <- sample(1:figusTotal,1, replace = T)
if(!(fig %in% albun_en_proceso)){
albun_en_proceso[fig] <- fig
}
compra_paquete <- compra_paquete + 1
}
return(compra_paquete)
}
cuantasFigus(6)
cuantasFigus(6)
cuantasFigus(6)
cuantasFigus(6)
cuantasFigus(6)
cuantasFigus(6)
cuantasFigus(6)
?replicate()
Nrep <- 1000
sim_cuantas_figuas <- rep(NaN,Nrep)
for (i in 1:Nrep) {
sim_cuantas_figuas[i] <- cuantasFigus(6)
}
hist(sim_cuantas_figuas)
media_sim <- mean(sim_cuantas_figuas)
media_sim
cumsum(sim_cuantas_figuas[sim_cuantas_figuas <= 16])
length(sim_cuantas_figuas[sim_cuantas_figuas <= 16])
p_x_<_16 <- length(sim_cuantas_figuas[sim_cuantas_figuas <= 16])/ Nrep
p_x_16 <- length(sim_cuantas_figuas[sim_cuantas_figuas <= 16])/ Nrep
quantile(sim_cuantas_figuas,0.9)
length(sim_cuantas_figuas[sim_cuantas_figuas <= 24])/ Nrep
q24 <- quantile(sim_cuantas_figuas,0.9)
citation()
citation("gplot2")
citation("ggplot2")
?quantile
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
# source(root$find_file("Entrega_Final/df_total_filtered.Rda")) ## me tira un error aca, no se poque lo voy a esta resolviendo
load("./df_total_filtered.Rda")
library(tidyverse)
d <- df_total %>%
select(!c(RelyOn,
Problems,
ConfKey1,
ConfKey2,
ConfKey3,
ConfKey4,
discrimination_is_correct,
confidence_key,
trials,
PointDifference,
ReacTime_DiscTask,
ReacTime_ConfTask)) %>%
distinct(Participant,.keep_all = TRUE)
plot(density(d$mc))
d %>%  ## no me estarian saliendo las leyendas, despues reviso
select(ConfMean,PC,Participant) %>%
# normalizo el promedio de confianza por sujeto para que este en una escala similar a la del desempeno
mutate(ConfMean = ConfMean/4, nr = row_number()) %>%
arrange(ConfMean) %>%
mutate(nr = row_number()) %>%
ggplot(aes(x= nr)) +
geom_point(aes(y=ConfMean), size = 2, color = "black") +
geom_point(aes(y=PC), size = 2, color = "grey")+
scale_x_continuous(expand = expansion(mult = c(0.01, 0.01))) +
scale_y_continuous(expand = expansion(mult = c(0.01, 0.1))) +
theme(axis.line = element_line(colour = "black"),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
plot.margin = margin(1, 1,1, 1, "cm"),
legend.text =  element_text(size = 25),
legend.position = c(0.7, 0.2),
legend.background = element_blank(),
legend.key = element_blank(),
legend.title = element_blank(),
panel.background = element_blank(),
axis.text.x = element_text(size = 30),
axis.text.y = element_text(size = 30),
axis.title.x = element_blank(),
axis.title.y = element_blank())
model <- glm(overconfidence ~ DomainAntagonism +
DomainDetachment +
DomainDisinhibition +
DomainNegativeAffect +
DomainPsychoticism,
family=binomial(link='logit'),
data=d)
d <- d %>%
mutate(ConfMean.norm = ConfMean/4,
overconfidence = ifelse(ConfMean.norm > 0.72, 1, 0))
# veo cuantos hay
d %>%
summarise(n= sum(overconfidence))
# hay 81 participantes con alta confianza, lo que nos da 143 con baja confianza
model <- glm(overconfidence ~ DomainAntagonism +
DomainDetachment +
DomainDisinhibition +
DomainNegativeAffect +
DomainPsychoticism,
family=binomial(link='logit'),
data=d)
summary(model)
model2 <- glm(overconfidence ~ DomainAntagonism +
DomainDetachment +
DomainDisinhibition +
DomainNegativeAffect +
DomainPsychoticism +
gender +
age,
family=binomial(link='logit'),
data=d)
summary(model2)
domain_columns <- colnames(d)[str_detect(colnames(d), pattern = 'Domain')]
sapply(
1:5, function(x) combn(domain_columns, x, simplify = F) %>%
lapply(function(y) str_flatten(y, ' + ')) %>%
unlist()
)  %>% unlist()
single_domain_formula <- paste0(
'overconfidence ~ ', domain_columns
)
single_domain_formula
full_domain_formula <- as.formula(
paste0(
'overconfidence ~ ', str_flatten(domain_columns, ' + ')
)
)
full_domain_formula
d$gender <- ifelse(d$gender == "Masculino",1,0)
d_mat <- d %>%
select(!c(Participant,
DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc)) %>%
data.matrix()
library(glmnet)
glmnet(d_mat, d$overconfidence, family = "binomial", alpha = 0, lambda = NULL)
Ridge_Facetas <- glmnet(d_mat, d$overconfidence, family = "binomial",
alpha = 0, lambda = NULL)
train <- d %>% sample_n(size = (nrow(d)-1))
head(train)
test  <- anti_join(d, train, by = 'Participant ')
test  <- anti_join(d, train, by = 'Participant')
head(Ridge_Facetas)
Ridge_Facetas$lambda
coef(Ridge_Facetas, Ridge_Facetas$lambda.min)
Ridge_Facetas$lambda.min
lala <- coef(Ridge_Facetas, Ridge_Facetas$lambda)
lala[[1]]
lala[1]
View(Ridge_Facetas)
View(lala)
str(lala)
lala
plot(Ridge_Facetas)
plot(Ridge_Facetas)
print(Ridge_Facetas)
coef(Ridge_Facetas, s = 0.05)
print(Ridge_Facetas)
coef(Ridge_Facetas, s = 331.20)
print(Ridge_Facetas)
lala_spam <- print(Ridge_Facetas)
lala_spam$Lambda
Ridge_Facetas$lambda
Ridge_Facetas$lambda
coef(Ridge_Facetas, s = lambdas[1])
lambdas
lambdas <- Ridge_Facetas$lambda
coef(Ridge_Facetas, s = lambdas[1])
# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
select(!c(Participant,
DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc,
ConfMean.norm,
overconfidence))
coef(modelo, s = lambdas[1])
modelo <- glmnet(d_mat, d$overconfidence, family = "binomial",
alpha = 0, lambda = NULL)
# tomo los lambdas generados por el modelo
lambdas <- modelo$lambda
# obtengo el modelo que genera cada lambda
coef(modelo, s = lambdas[1])
coef(modelo, s = lambdas[1])
# datos de entrenamiento (todos menos 1)
train <- d.regre.regul.facetas %>% sample_n(size = (nrow(d.regre.regul.facetas)-1))
# agarro el dato que quedo para el testeo
test  <- anti_join(d.regre.regul.facetas, train, by = 'Participant')
# corro el modelo
modelo <- glmnet(d_mat, d$overconfidence, family = "binomial",
alpha = 0, lambda = NULL)
lambdas <- modelo$lambda
coef(modelo, s = lambdas[1])
modelo$lambda
seq(0.01, 100 , by = 0.01)
seq(0.01, 100 , by = 0.01*2)
seq(0.01, 100 , by = 0.01*3)
seq(0.01, 100 , by = 0.01*4)
seq(0.01, 100 , by = 0.01*5)
seq(0.01, 100 , by = 0.01*10)
seq(0.01, 100 , by = 0.01*10)
seq(0.01, 100 , by = 0.01*10)
0.01*10
0.01*10*10
0.01*10*10*10
modelo$lambda
seq(0.01, 10 , by = 0.01)
seq(0.01, 10 , by = 0.1)
seq(0.01, 10 , length.out = 100)
seq(0.01, 10 , length.out = 300)
# creo una secuencua de posibles lambdas
seq(0.01, 20 , length.out = 300)
# creo una secuencua de posibles lambdas
posibles_lambdas <- seq(0.01, 20 , length.out = 300)
# agrego una variable ID (participantes la saque para correr el modelo)
d.regre.regul.facetas <- d.regre.regul.facetas %>%
mutate(id = row_number())
# datos de entrenamiento (todos menos 1)
train <- d.regre.regul.facetas %>% sample_n(size = (nrow(d.regre.regul.facetas)-1))
# agarro el dato que quedo para el testeo
test  <- anti_join(d.regre.regul.facetas, train, by = 'id')
# transformo en matrix
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo
modelo <- glmnet(train.m, d$overconfidence, family = "binomial",
alpha = 0, lambda = posibles_lambdas)
# corro el modelo
modelo <- glmnet(train.m, train$overconfidence, family = "binomial",
alpha = 0, lambda = posibles_lambdas)
head(train)
# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
select(!c(Participant,
DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc,
ConfMean.norm))
d_mat <- d.regre.regul.facetas %>%
data.matrix()
# creo una secuencua de posibles lambdas
posibles_lambdas <- seq(0.01, 20 , length.out = 300)
# agrego una variable ID (participantes la saque para correr el modelo)
d.regre.regul.facetas <- d.regre.regul.facetas %>%
mutate(id = row_number())
# datos de entrenamiento (todos menos 1)
train <- d.regre.regul.facetas %>% sample_n(size = (nrow(d.regre.regul.facetas)-1))
# agarro el dato que quedo para el testeo
test  <- anti_join(d.regre.regul.facetas, train, by = 'id')
# ahora les saco overconfidence (ya que no tiene que ir como predictor)
train <- train %>%
select(!overconfidence)
test <- test %>%
select(!overconfidence)
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo
modelo <- glmnet(train.m, train$overconfidence, family = "binomial",
alpha = 0, lambda = posibles_lambdas)
# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
select(!c(Participant,
DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc,
ConfMean.norm))
d_mat <- d.regre.regul.facetas %>%
data.matrix()
# creo una secuencua de posibles lambdas
posibles_lambdas <- seq(0.01, 20 , length.out = 300)
# agrego una variable ID (participantes la saque para correr el modelo)
d.regre.regul.facetas <- d.regre.regul.facetas %>%
mutate(id = row_number())
# datos de entrenamiento (todos menos 1)
train <- d.regre.regul.facetas %>% sample_n(size = (nrow(d.regre.regul.facetas)-1))
# agarro el dato que quedo para el testeo
test  <- anti_join(d.regre.regul.facetas, train, by = 'id')
# ahora les saco overconfidence (ya que no tiene que ir como predictor)
# Aunque primero lo guardo, para despues testearlo
y <- train$overconfidence
train <- train %>%
select(!overconfidence)
test <- test %>%
select(!overconfidence)
# transformo en matrix
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo
modelo <- glmnet(train.m, y, family = "binomial",
alpha = 0, lambda = posibles_lambdas)
lambdas <- modelo$lambda
lambdas
posibles_lambdas
posibles_lambdas %in% lambdas
error <- rep(NaN, length(nrow(d.regre.regul.facetas)))
# creo una secuencua de posibles lambdas
posibles_lambdas <- seq(0.01, 20 , length.out = 300)
for (j in 1:nrow(d.regre.regul.facetas)){
# agrego una variable ID (participantes la saque para correr el modelo)
d.regre.regul.facetas <- d.regre.regul.facetas %>%
mutate(id = row_number())
# datos de entrenamiento (todos menos 1)
train <- d.regre.regul.facetas %>%
filter(id != d.regre.regul.facetas$id[j])
# agarro el dato que quedo para el testeo
test  <- anti_join(d.regre.regul.facetas, train, by = 'id')
# Guardo las observaciones de overconfidence en entrenamiento y testeo(para entrenar el modelo y testearlo)
y.train <- train$overconfidence
y.test <- test$overconfidence
# ahora les saco overconfidence (ya que no tiene que ir como predictor)
train <- train %>%
select(!overconfidence)
test <- test %>%
select(!overconfidence)
# transformo en matrix
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo con los datos de entrenamiento
modelo <- glmnet(train.m, y.train, family = "binomial",
alpha = 0, lambda = posibles_lambdas)
# tomo los lambdas generados por el modelo (los mismo que le puse, pero tomo su orden)
lambdas <- modelo$lambda
# Creo la variable en la que voy a guardar el error para cada lambda
error <- rep(NaN, length(nrow(d.regre.regul.facetas)))
for (i in 1:length(lambdas)) {
# obtengo el modelo que genera cada lambda
lambda_i <- coef(modelo, s = lambdas[i])
# hago prediccion sobre la data de testeo
probabilities <- lambda_i %>% predict(new = test.m, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
caso.observado <- y.test
error[i] <- mean(caso.prediccion == caso.observado) # revisar que sacar aca
}
}
