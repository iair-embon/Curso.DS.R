<<<<<<< HEAD
# creo una secuencua de posibles lambdas
posibles_lambdas <- seq(0.01, 20 , length.out = 300)
for (j in 1:nrow(d.regre.regul.facetas)){
# agrego una variable ID (participantes la saque para correr el modelo)
d.regre.regul.facetas <- d.regre.regul.facetas %>%
mutate(id = row_number())
# datos de entrenamiento (todos menos 1)
train <- d.regre.regul.facetas %>%
filter(id != d.regre.regul.facetas$id[j])
# agarro el dato que quedo para el testeo
test  <- anti_join(d.regre.regul.facetas, train, by = 'id')
# Guardo las observaciones de overconfidence en entrenamiento y testeo(para entrenar el modelo y testearlo)
y.train <- train$overconfidence
y.test <- test$overconfidence
# ahora les saco overconfidence (ya que no tiene que ir como predictor)
train <- train %>%
select(!overconfidence)
test <- test %>%
select(!overconfidence)
=======
filter(Participant != df$Participant[j])
# agarro el dato que quedo para el testeo
test  <- anti_join(df, train, by = 'Participant')
# Guardo las observaciones de genero en entrenamiento y testeo (para entrenar el modelo y testearlo)
y.train <- train$gender
y.test <- test$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
train <- train %>% select(!c(gender,Participant))
test <- test %>% select(!c(gender,Participant))
>>>>>>> 975eea94a86b7c31bace413458805efcc2492ee3
# transformo en matrix
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo con los datos de entrenamiento
modelo <- glmnet(train.m, y.train, family = "binomial",
alpha = alpha.dado, lambda = posibles_lambdas)
# hago prediccion sobre la data de testeo
probabilities <- modelo %>% predict(newx = test.m, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
matriz.errores[j,] <- predicted.classes == y.test
}
# saco los root mean squared errors para cada lambda (en principio, solo vamos a usar accuracy)
# lambda.RMSE <- sqrt(((rowSums(matriz.errores))**2)/nrow(df))
list_return <- list("matriz.errores" = matriz.errores,
"lambdas" = posibles_lambdas)
return(list_return)
}
<<<<<<< HEAD
library(tidyverse)
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
# source(root$find_file("Entrega_Final/df_total_filtered.Rda")) ## me tira un error aca, no se poque lo voy a esta resolviendo
load("./df_total_filtered.Rda")
str(df_total)
print(length(unique(df_total$Participant)))
hist(df_total$confidence_key)
library(tidyverse)
d <- df_total %>%
select(!c(RelyOn,
Problems,
ConfKey1,
ConfKey2,
ConfKey3,
ConfKey4,
discrimination_is_correct,
confidence_key,
trials,
PointDifference,
ReacTime_DiscTask,
ReacTime_ConfTask)) %>%
distinct(Participant,.keep_all = TRUE)
plot(density(d$mc))
d %>%  ## no me estarian saliendo las leyendas, despues reviso
select(ConfMean,PC,Participant) %>%
# normalizo el promedio de confianza por sujeto para que este en una escala similar a la del desempeno
mutate(ConfMean = ConfMean/4, nr = row_number()) %>%
arrange(ConfMean) %>%
mutate(nr = row_number()) %>%
ggplot(aes(x= nr)) +
geom_point(aes(y=ConfMean), size = 2, color = "black") +
geom_point(aes(y=PC), size = 2, color = "grey")+
scale_x_continuous(expand = expansion(mult = c(0.01, 0.01))) +
scale_y_continuous(expand = expansion(mult = c(0.01, 0.1))) +
theme(axis.line = element_line(colour = "black"),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
plot.margin = margin(1, 1,1, 1, "cm"),
legend.text =  element_text(size = 25),
legend.position = c(0.7, 0.2),
legend.background = element_blank(),
legend.key = element_blank(),
legend.title = element_blank(),
panel.background = element_blank(),
axis.text.x = element_text(size = 30),
axis.text.y = element_text(size = 30),
axis.title.x = element_blank(),
axis.title.y = element_blank())
d <- d %>%
mutate(ConfMean.norm = ConfMean/4,
overconfidence = ifelse(ConfMean.norm > 0.72, 1, 0))
# veo cuantos hay
d %>%
summarise(n= sum(overconfidence))
# hay 81 participantes con alta confianza, lo que nos da 143 con baja confianza
d$gender <- ifelse(d$gender == "Masculino",1,0)
model <- glm(overconfidence ~ DomainAntagonism +
DomainDetachment +
DomainDisinhibition +
DomainNegativeAffect +
DomainPsychoticism,
family=binomial(link='logit'),
data=d)
summary(model)
model2 <- glm(overconfidence ~ DomainAntagonism +
DomainDetachment +
DomainDisinhibition +
DomainNegativeAffect +
DomainPsychoticism +
gender +
age,
family=binomial(link='logit'),
data=d)
summary(model2)
# creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
matriz.errores <- matrix(data=NA,nrow= nrow(d.regre.regul.facetas),
ncol= length(posibles_lambdas))
# creo una secuencua de posibles lambdas
posibles_lambdas <- seq(0.01, 20 , length.out = 300)
# creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
matriz.errores <- matrix(data=NA,nrow= nrow(d.regre.regul.facetas),
ncol= length(posibles_lambdas))
j <- 1
# datos de entrenamiento (todos menos 1)
train <- d.regre.regul.facetas %>%
filter(Participant != d.regre.regul.facetas$Participant[j])
=======
>>>>>>> 975eea94a86b7c31bace413458805efcc2492ee3
# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
select(!c(DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc,
overconfidence))
library(tidyverse)
library(glmnet)
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
load("./df_total_filtered.Rda")
d$gender <- ifelse(d$gender == "Masculino",1,0)
model <- glm(gender ~ DomainAntagonism +
DomainDetachment +
DomainDisinhibition +
DomainNegativeAffect +
DomainPsychoticism,
family=binomial(link='logit'),
data=d)
summary(model)
model2 <- glm(gender ~ DomainAntagonism +
DomainDetachment +
DomainDisinhibition +
DomainNegativeAffect +
DomainPsychoticism +
age,
family=binomial(link='logit'),
data=d)
summary(model2)
####
LOOCV.fun.glmnet <- function(df, alpha.dado){
### Primero creo una secuencua de posibles lambdas, desde un modelo desechable
# Guardo las observaciones de genero
y <- df$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
df.lambda <- df %>% select(!c(gender,Participant))
# transformo en matrix
df.lambda.m <- df.lambda %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.lambda <- glmnet(df.lambda.m, y , family = "binomial",
alpha = alpha.dado)
posibles_lambdas <- modelo.lambda$lambda
# creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
matriz.errores <- matrix(data=NA,nrow= nrow(df),
ncol= length(posibles_lambdas))
for (j in 1:nrow(df)){
# datos de entrenamiento (todos menos 1)
train <- df %>%
filter(Participant != df$Participant[j])
# agarro el dato que quedo para el testeo
test  <- anti_join(df, train, by = 'Participant')
# Guardo las observaciones de genero en entrenamiento y testeo (para entrenar el modelo y testearlo)
y.train <- train$gender
y.test <- test$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
train <- train %>% select(!c(gender,Participant))
test <- test %>% select(!c(gender,Participant))
# transformo en matrix
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo con los datos de entrenamiento
modelo <- glmnet(train.m, y.train, family = "binomial",
alpha = alpha.dado, lambda = posibles_lambdas)
# hago prediccion sobre la data de testeo
probabilities <- modelo %>% predict(newx = test.m, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
matriz.errores[j,] <- predicted.classes == y.test
}
# saco los root mean squared errors para cada lambda (en principio, solo vamos a usar accuracy)
# lambda.RMSE <- sqrt(((rowSums(matriz.errores))**2)/nrow(df))
list_return <- list("matriz.errores" = matriz.errores,
"lambdas" = posibles_lambdas)
return(list_return)
}
# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
select(!c(DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc))
opt_alpha_lambda <- function(df){
# Creo los vectores que van a contener todos los lambdas, alphas y sus respectivos accuracy
alphas.usados <- c()
lambdas.usados <- c()
accuracy <- c()
# creo los alphas que vamos a usar
muchos.alphas <- seq(0,1, by = 0.1)
# itero por varios alphas
for (i in 1:length(muchos.alphas)) {
alpha.dado <- muchos.alphas[i]
# Hago LOOCV para elegir varios lambdas
lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
matriz.errores <- lambdaOptimo_facetas$matriz.errores
# saco la proporcion de aciertos
accuracy <- c(accuracy, colMeans(matriz.errores))
alphas.usados <- c(alphas.usados, rep(alpha.dado, length(lambdaOptimo_facetas$lambda.accuracy)))
lambdas.usados <- c(lambdas.usados,lambdaOptimo_facetas$lambdas)
}
df_alp_lambd_accuracy <- data.frame(alpha = alphas.usados,
lambda = lambdas.usados,
accuracy = accuracy)
return(df_alp_lambd_accuracy)
}
opt_alpha_lambda.df <- opt_alpha_lambda(d.regre.regul.facetas)
opt_alpha_lambda.df <- opt_alpha_lambda(d.regre.regul.facetas)
df <- d.regre.regul.facetas
j <- 1
# Creo los vectores que van a contener todos los lambdas, alphas y sus respectivos accuracy
alphas.usados <- c()
lambdas.usados <- c()
accuracy <- c()
# creo los alphas que vamos a usar
muchos.alphas <- seq(0,1, by = 0.1)
alpha.dado <- muchos.alphas[i]
# Hago LOOCV para elegir varios lambdas
lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
y <- df$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
df.lambda <- df %>% select(!c(gender,Participant))
# transformo en matrix
df.lambda.m <- df.lambda %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.lambda <- glmnet(df.lambda.m, y , family = "binomial",
alpha = alpha.dado)
glmnet(df.lambda.m, y , family = "binomial",
alpha = alpha.dado)
is.na(df.lambda.m)
sum(is.na(df.lambda.m))
# Corro el modelo y obtengo el lambda
modelo.lambda <- glmnet(df.lambda.m, y , family = "binomial",
alpha = alpha.dado)
df$gender
d$gender <- ifelse(d$gender == "Masculino",1,0)
d$gender
library(tidyverse)
library(glmnet)
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
load("./df_total_filtered.Rda")
d$gender <- ifelse(d$gender == "Masculino",1,0)
d$gender <- ifelse(d$gender == "Masculino",1,0)
d$gender
library(tidyverse)
library(glmnet)
library(tidyverse)
library(glmnet)
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
load("./df_total_filtered.Rda")
d <- df_total %>%
select(!c(RelyOn,
Problems,
ConfKey1,
ConfKey2,
ConfKey3,
ConfKey4,
discrimination_is_correct,
confidence_key,
trials,
PointDifference,
ReacTime_DiscTask,
ReacTime_ConfTask)) %>%
distinct(Participant,.keep_all = TRUE)
d$gender <- ifelse(d$gender == "Masculino",1,0)
d$gender
library(tidyverse)
library(glmnet)
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
load("./df_total_filtered.Rda")
d <- df_total %>%
select(!c(RelyOn,
Problems,
ConfKey1,
ConfKey2,
ConfKey3,
ConfKey4,
discrimination_is_correct,
confidence_key,
trials,
PointDifference,
ReacTime_DiscTask,
ReacTime_ConfTask)) %>%
distinct(Participant,.keep_all = TRUE)
d$gender <- ifelse(d$gender == "Masculino",1,0)
model <- glm(gender ~ DomainAntagonism +
DomainDetachment +
DomainDisinhibition +
DomainNegativeAffect +
DomainPsychoticism,
family=binomial(link='logit'),
data=d)
summary(model)
model2 <- glm(gender ~ DomainAntagonism +
DomainDetachment +
DomainDisinhibition +
DomainNegativeAffect +
DomainPsychoticism +
age,
family=binomial(link='logit'),
data=d)
summary(model2)
####
LOOCV.fun.glmnet <- function(df, alpha.dado){
### Primero creo una secuencua de posibles lambdas, desde un modelo desechable
# Guardo las observaciones de genero
y <- df$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
df.lambda <- df %>% select(!c(gender,Participant))
# transformo en matrix
df.lambda.m <- df.lambda %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.lambda <- glmnet(df.lambda.m, y , family = "binomial",
alpha = alpha.dado)
posibles_lambdas <- modelo.lambda$lambda
# creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
matriz.errores <- matrix(data=NA,nrow= nrow(df),
ncol= length(posibles_lambdas))
for (j in 1:nrow(df)){
# datos de entrenamiento (todos menos 1)
train <- df %>%
filter(Participant != df$Participant[j])
# agarro el dato que quedo para el testeo
test  <- anti_join(df, train, by = 'Participant')
# Guardo las observaciones de genero en entrenamiento y testeo (para entrenar el modelo y testearlo)
y.train <- train$gender
y.test <- test$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
train <- train %>% select(!c(gender,Participant))
test <- test %>% select(!c(gender,Participant))
# transformo en matrix
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo con los datos de entrenamiento
modelo <- glmnet(train.m, y.train, family = "binomial",
alpha = alpha.dado, lambda = posibles_lambdas)
# hago prediccion sobre la data de testeo
probabilities <- modelo %>% predict(newx = test.m, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
matriz.errores[j,] <- predicted.classes == y.test
}
# saco los root mean squared errors para cada lambda (en principio, solo vamos a usar accuracy)
# lambda.RMSE <- sqrt(((rowSums(matriz.errores))**2)/nrow(df))
list_return <- list("matriz.errores" = matriz.errores,
"lambdas" = posibles_lambdas)
return(list_return)
}
# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
select(!c(DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc))
opt_alpha_lambda <- function(df){
# Creo los vectores que van a contener todos los lambdas, alphas y sus respectivos accuracy
alphas.usados <- c()
lambdas.usados <- c()
accuracy <- c()
# creo los alphas que vamos a usar
muchos.alphas <- seq(0,1, by = 0.1)
# itero por varios alphas
for (i in 1:length(muchos.alphas)) {
alpha.dado <- muchos.alphas[i]
# Hago LOOCV para elegir varios lambdas
lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
matriz.errores <- lambdaOptimo_facetas$matriz.errores
# saco la proporcion de aciertos
accuracy <- c(accuracy, colMeans(matriz.errores))
alphas.usados <- c(alphas.usados, rep(alpha.dado, length(lambdaOptimo_facetas$lambda.accuracy)))
lambdas.usados <- c(lambdas.usados,lambdaOptimo_facetas$lambdas)
}
df_alp_lambd_accuracy <- data.frame(alpha = alphas.usados,
lambda = lambdas.usados,
accuracy = accuracy)
return(df_alp_lambd_accuracy)
}
opt_alpha_lambda.df <- opt_alpha_lambda(d.regre.regul.facetas)
opt_alpha_lambda <- function(df){
# Creo los vectores que van a contener todos los lambdas, alphas y sus respectivos accuracy
alphas.usados <- c()
lambdas.usados <- c()
accuracy <- c()
# creo los alphas que vamos a usar
muchos.alphas <- seq(0,1, by = 0.1)
# itero por varios alphas
for (i in 1:length(muchos.alphas)) {
alpha.dado <- muchos.alphas[i]
# Hago LOOCV para elegir varios lambdas
lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
matriz.errores <- lambdaOptimo_facetas$matriz.errores
# saco la proporcion de aciertos
accuracy <- c(accuracy, colMeans(matriz.errores))
alphas.usados <- c(alphas.usados, rep(alpha.dado, length(lambdaOptimo_facetas$lambda.accuracy)))
lambdas.usados <- c(lambdas.usados,lambdaOptimo_facetas$lambdas)
}
df_alp_lambd_accuracy <- data.frame(alpha = alphas.usados,
lambda = lambdas.usados,
accuracy = accuracy)
return(df_alp_lambd_accuracy)
}
opt_alpha_lambda.df <- opt_alpha_lambda(d.regre.regul.facetas)
df <- d.regre.regul.facetas
i <- 1
# Creo los vectores que van a contener todos los lambdas, alphas y sus respectivos accuracy
alphas.usados <- c()
lambdas.usados <- c()
accuracy <- c()
# creo los alphas que vamos a usar
muchos.alphas <- seq(0,1, by = 0.1)
alpha.dado <- muchos.alphas[i]
alpha.dado
# Hago LOOCV para elegir varios lambdas
lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
# Hago LOOCV para elegir varios lambdas
lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
matriz.errores <- lambdaOptimo_facetas$matriz.errores
# saco la proporcion de aciertos
accuracy <- c(accuracy, colMeans(matriz.errores))
accuracy
opt_alpha_lambda <- function(df){
# Creo los vectores que van a contener todos los lambdas, alphas y sus respectivos accuracy
alphas.usados <- c()
lambdas.usados <- c()
accuracy <- c()
# creo los alphas que vamos a usar
muchos.alphas <- seq(0,1, by = 0.1)
# itero por varios alphas
for (i in 1:length(muchos.alphas)) {
alpha.dado <- muchos.alphas[i]
# Hago LOOCV para elegir varios lambdas
lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
matriz.errores <- lambdaOptimo_facetas$matriz.errores
# saco la proporcion de aciertos
accuracy <- c(accuracy, colMeans(matriz.errores))
alphas.usados <- c(alphas.usados, rep(alpha.dado, length(accuracy)))
lambdas.usados <- c(lambdas.usados,lambdaOptimo_facetas$lambdas)
}
df_alp_lambd_accuracy <- data.frame(alpha = alphas.usados,
lambda = lambdas.usados,
accuracy = accuracy)
return(df_alp_lambd_accuracy)
}
opt_alpha_lambda.df <- opt_alpha_lambda(d.regre.regul.facetas)
df <- d.regre.regul.facetas
i <- 1
# Creo los vectores que van a contener todos los lambdas, alphas y sus respectivos accuracy
alphas.usados <- c()
lambdas.usados <- c()
accuracy <- c()
# creo los alphas que vamos a usar
muchos.alphas <- seq(0,1, by = 0.1)
alpha.dado <- muchos.alphas[i]
# Hago LOOCV para elegir varios lambdas
lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
matriz.errores <- lambdaOptimo_facetas$matriz.errores
# saco la proporcion de aciertos
accuracy <- c(accuracy, colMeans(matriz.errores))
accuracy
matriz.errores
alphas.usados <- c(alphas.usados, rep(alpha.dado, length(accuracy)))
alphas.usados
lambdas.usados <- c(lambdas.usados,lambdaOptimo_facetas$lambdas)
lambdas.usados
accuracy
alphas.usados
lambdas.usados
for (i in 1:length(muchos.alphas)) {
alpha.dado <- muchos.alphas[i]
# Hago LOOCV para elegir varios lambdas
lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
matriz.errores <- lambdaOptimo_facetas$matriz.errores
# saco la proporcion de aciertos
accuracy <- c(accuracy, colMeans(matriz.errores))
alphas.usados <- c(alphas.usados, rep(alpha.dado, length(accuracy)))
lambdas.usados <- c(lambdas.usados,lambdaOptimo_facetas$lambdas)
}
opt_alpha_lambda <- function(df){
# Creo los vectores que van a contener todos los lambdas, alphas y sus respectivos accuracy
alphas.usados <- c()
lambdas.usados <- c()
accuracy <- c()
# creo los alphas que vamos a usar
muchos.alphas <- seq(0,1, by = 0.1)
# itero por varios alphas
for (i in 1:length(muchos.alphas)) {
alpha.dado <- muchos.alphas[i]
# Hago LOOCV para elegir varios lambdas
lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
matriz.errores <- lambdaOptimo_facetas$matriz.errores
# saco la proporcion de aciertos
accuracy <- c(accuracy, colMeans(matriz.errores))
lambdas.usados <- c(lambdas.usados,lambdaOptimo_facetas$lambdas)
alphas.usados <- c(alphas.usados, rep(alpha.dado, length(lambdaOptimo_facetas$lambdas)))
}
df_alp_lambd_accuracy <- data.frame(alpha = alphas.usados,
lambda = lambdas.usados,
accuracy = accuracy)
return(df_alp_lambd_accuracy)
}
opt_alpha_lambda.df <- opt_alpha_lambda(d.regre.regul.facetas)
View(opt_alpha_lambda.df)
index.opt.param <- which.min(opt_alpha_lambda.df$accuracy)
index.opt.param
lambda.optimo <- opt_alpha_lambda.df$lambda[index.opt.param]
alpha.optimo <- opt_alpha_lambda.df$alpha[index.opt.param]
lambda.optimo
alpha.optimo
y <- d.regre.regul.facetas$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(gender,Participant))
# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.facetas <- glmnet(d.regre.regul.facetas.prepro.m, y,
family = "binomial",
alpha = alpha.optimo, lambda = lambda.optimo)
coef(modelo.facetas)
# me fijo el lambda optimo que me elije el modelo por si solo usando funciones de la libreria, para alpha = 1
modelo.facetas2 <- glmnet(d.regre.regul.facetas.prepro.m, y,
family = "binomial",
alpha = 1)
# Corro el modelo y obtengo el lambda
modelo.facetas <- glmnet(d.regre.regul.facetas.prepro.m, y,
family = "binomial",
alpha = alpha.optimo, lambda = lambda.optimo)
coef(modelo.facetas)
# me fijo el lambda optimo que me elije el modelo por si solo usando funciones de la libreria, para alpha = 1
modelo.facetas2 <- glmnet(d.regre.regul.facetas.prepro.m, y,
family = "binomial",
alpha = 0.1)
set.seed(1010)
cvfit <- cv.glmnet(d.regre.regul.facetas.prepro.m,y, type.measure = "mse", nfolds = 10)
cvfit <- cv.glmnet(d.regre.regul.facetas.prepro.m,y, type.measure = "deviance", nfolds = 10)
cvfit$lambda.min
lambda.optimo
cvfit <- cv.glmnet(d.regre.regul.facetas.prepro.m,y, type.measure = "auc", nfolds = 10)
cvfit$lambda.min
cvfit <- cv.glmnet(d.regre.regul.facetas.prepro.m,y, type.measure = "deviance", nfolds = 10)
cvfit$lambda.min
coef(cvfit, s = "lambda.min")
nrow(d.regre.regul.facetas)
cvfit <- cv.glmnet(d.regre.regul.facetas.prepro.m,y, type.measure = "auc", nfolds = nrow(d.regre.regul.facetas))
cvfit$lambda.min
lambda.optimo
cvfit <- cv.glmnet(d.regre.regul.facetas.prepro.m,y, type.measure = "mse", nfolds = nrow(d.regre.regul.facetas))
cvfit <- cv.glmnet(d.regre.regul.facetas.prepro.m,y, type.measure = "mse", nfolds = nrow(d.regre.regul.facetas))
cvfit$lambda.min
<<<<<<< HEAD
plot(cvfit)
log(20)
lambda.RMSE
which(lambda.RMSE)
which(lambda.RMSE.min)
which(min(lambda.RMSE))
which(lambda.RMSE,min(lambda.RMSE))
which.min(lambda.RMSE)
LOOCV.fun.glmnet <- function(df){
# creo una secuencua de posibles lambdas
posibles_lambdas <- seq(0.01, 20 , length.out = 300)
# creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
matriz.errores <- matrix(data=NA,nrow= nrow(df),
ncol= length(posibles_lambdas))
for (j in 1:nrow(df)){
# datos de entrenamiento (todos menos 1)
train <- d.regre.regul.facetas %>%
filter(Participant != df$Participant[j])
# agarro el dato que quedo para el testeo
test  <- anti_join(df, train, by = 'Participant')
# Guardo las observaciones de overconfidence en entrenamiento y testeo (para entrenar el modelo y testearlo)
y.train <- train$overconfidence
y.test <- test$overconfidence
# ahora les saco overconfidence y Participant (ya que no tienen que ir como predictores)
train <- train %>% select(!c(overconfidence,Participant))
test <- test %>% select(!c(overconfidence,Participant))
# transformo en matrix
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo con los datos de entrenamiento
modelo <- glmnet(train.m, y.train, family = "binomial",
alpha = 0, lambda = posibles_lambdas)
# hago prediccion sobre la data de testeo
probabilities <- modelo %>% predict(newx = test.m, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
matriz.errores[j,] <- predicted.classes == y.test
}
# saco los root mean squared errors para cada lambda
lambda.RMSE <- sqrt(((rowSums(matriz.errores))**2)/nrow(df))
return(lambda.RMSE)
}
library(glmnet)
d.regre.regul.facetas
# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
select(!c(DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc,
ConfMean.norm))
lambdaOptimo_facetas <- LOOCV.fun.glmnet(d.regre.regul.facetas)
lambdaOptimo_facetas <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0)
# Model accuracy
matriz.errores[j,] <- predicted.classes == y.test
LOOCV.fun.glmnet <- function(df, alpha.dado){
# creo una secuencua de posibles lambdas
posibles_lambdas <- seq(0.01, 20 , length.out = 300)
# creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
matriz.errores <- matrix(data=NA,nrow= nrow(df),
ncol= length(posibles_lambdas))
for (j in 1:nrow(df)){
# datos de entrenamiento (todos menos 1)
train <- d.regre.regul.facetas %>%
filter(Participant != df$Participant[j])
# agarro el dato que quedo para el testeo
test  <- anti_join(df, train, by = 'Participant')
# Guardo las observaciones de overconfidence en entrenamiento y testeo (para entrenar el modelo y testearlo)
y.train <- train$overconfidence
y.test <- test$overconfidence
# ahora les saco overconfidence y Participant (ya que no tienen que ir como predictores)
train <- train %>% select(!c(overconfidence,Participant))
test <- test %>% select(!c(overconfidence,Participant))
# transformo en matrix
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo con los datos de entrenamiento
modelo <- glmnet(train.m, y.train, family = "binomial",
alpha = alpha.dado , lambda = posibles_lambdas)
# hago prediccion sobre la data de testeo
probabilities <- modelo %>% predict(newx = test.m, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
matriz.errores[j,] <- predicted.classes == y.test
}
# saco los root mean squared errors para cada lambda
lambda.RMSE <- sqrt(((rowSums(matriz.errores))**2)/nrow(df))
return(lambda.RMSE)
}
lambdaOptimo_facetas <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0)
lambdaOptimo_facetas
lambdaOptimo_facetas_ridge <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0)
lambdaOptimo_facetas_lasso <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 1)
lambdaOptimo_facetas_elastic
lambdaOptimo_facetas_elastic <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0.5)
lambdaOptimo_facetas_elastic
lambdaOptimo_facetas_lasso
load("D:/Windows/Descargas/Curso.DS.R/Entrega_Final/df_total_filtered.Rda")
str(df_total)
library(tidyverse)
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
# source(root$find_file("Entrega_Final/df_total_filtered.Rda")) ## me tira un error aca, no se poque lo voy a esta resolviendo
load("./df_total_filtered.Rda")
str(df_total)
print(length(unique(df_total$Participant)))
hist(df_total$confidence_key)
d <- df_total %>%
select(!c(RelyOn,
Problems,
ConfKey1,
ConfKey2,
ConfKey3,
ConfKey4,
discrimination_is_correct,
confidence_key,
trials,
PointDifference,
ReacTime_DiscTask,
ReacTime_ConfTask)) %>%
distinct(Participant,.keep_all = TRUE)
plot(density(d$mc))
d %>%  ## no me estarian saliendo las leyendas, despues reviso
select(ConfMean,PC,Participant) %>%
# normalizo el promedio de confianza por sujeto para que este en una escala similar a la del desempeno
mutate(ConfMean = ConfMean/4, nr = row_number()) %>%
arrange(ConfMean) %>%
mutate(nr = row_number()) %>%
ggplot(aes(x= nr)) +
geom_point(aes(y=ConfMean), size = 2, color = "black") +
geom_point(aes(y=PC), size = 2, color = "grey")+
scale_x_continuous(expand = expansion(mult = c(0.01, 0.01))) +
scale_y_continuous(expand = expansion(mult = c(0.01, 0.1))) +
theme(axis.line = element_line(colour = "black"),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
plot.margin = margin(1, 1,1, 1, "cm"),
legend.text =  element_text(size = 25),
legend.position = c(0.7, 0.2),
legend.background = element_blank(),
legend.key = element_blank(),
legend.title = element_blank(),
panel.background = element_blank(),
axis.text.x = element_text(size = 30),
axis.text.y = element_text(size = 30),
axis.title.x = element_blank(),
axis.title.y = element_blank())
=======
>>>>>>> 975eea94a86b7c31bace413458805efcc2492ee3
