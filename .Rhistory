lambda.RMSE <- sqrt(((rowSums(matriz.errores))**2)/nrow(df))
return(lambda.RMSE)
}
lambdaOptimo_facetas <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0)
lambdaOptimo_facetas
lambdaOptimo_facetas_ridge <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0)
lambdaOptimo_facetas_lasso <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 1)
lambdaOptimo_facetas_elastic
lambdaOptimo_facetas_elastic <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0.5)
lambdaOptimo_facetas_elastic
lambdaOptimo_facetas_lasso
load("D:/Windows/Descargas/Curso.DS.R/Entrega_Final/df_total_filtered.Rda")
str(df_total)
library(tidyverse)
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
# source(root$find_file("Entrega_Final/df_total_filtered.Rda")) ## me tira un error aca, no se poque lo voy a esta resolviendo
load("./df_total_filtered.Rda")
str(df_total)
print(length(unique(df_total$Participant)))
hist(df_total$confidence_key)
d <- df_total %>%
select(!c(RelyOn,
Problems,
ConfKey1,
ConfKey2,
ConfKey3,
ConfKey4,
discrimination_is_correct,
confidence_key,
trials,
PointDifference,
ReacTime_DiscTask,
ReacTime_ConfTask)) %>%
distinct(Participant,.keep_all = TRUE)
plot(density(d$mc))
d %>%  ## no me estarian saliendo las leyendas, despues reviso
select(ConfMean,PC,Participant) %>%
# normalizo el promedio de confianza por sujeto para que este en una escala similar a la del desempeno
mutate(ConfMean = ConfMean/4, nr = row_number()) %>%
arrange(ConfMean) %>%
mutate(nr = row_number()) %>%
ggplot(aes(x= nr)) +
geom_point(aes(y=ConfMean), size = 2, color = "black") +
geom_point(aes(y=PC), size = 2, color = "grey")+
scale_x_continuous(expand = expansion(mult = c(0.01, 0.01))) +
scale_y_continuous(expand = expansion(mult = c(0.01, 0.1))) +
theme(axis.line = element_line(colour = "black"),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
plot.margin = margin(1, 1,1, 1, "cm"),
legend.text =  element_text(size = 25),
legend.position = c(0.7, 0.2),
legend.background = element_blank(),
legend.key = element_blank(),
legend.title = element_blank(),
panel.background = element_blank(),
axis.text.x = element_text(size = 30),
axis.text.y = element_text(size = 30),
axis.title.x = element_blank(),
axis.title.y = element_blank())
library(tidyverse)
library(glmnet)
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
load("./df_total_filtered.Rda")
df_calibracion <- df_total %>%
group_by(Participant, confidence_key) %>%
summarise(prop_correcta = mean(discrimination_is_correct)) %>%
rename(ConfidenceKey = confidence_key)
df_calibracion.calculada <- df_total %>%
pivot_longer(cols = starts_with("ConfKey")) %>%
distinct(Participant, name, .keep_all = TRUE) %>%
select(Participant, name, value) %>%
mutate(ConfidenceKey = as.integer(str_extract(name, "\\d"))) %>%
left_join(df_calibracion) %>%
drop_na() %>%
mutate(ConfidenceKey = (ConfidenceKey+2)/6) %>%
group_by(Participant) %>%
mutate(Conf.norm = value / sum(value)) %>%
mutate( preCalibracion = value*(prop_correcta - ConfidenceKey)**2) %>%
summarise(Calibracion  = mean(preCalibracion))
d <- df_total %>%
select(!c(RelyOn,
Problems,
ConfKey1,
ConfKey2,
ConfKey3,
ConfKey4,
discrimination_is_correct,
confidence_key,
trials,
PointDifference,
ReacTime_DiscTask,
ReacTime_ConfTask)) %>%
distinct(Participant,.keep_all = TRUE)
# le agrego la variable calibracion
d <- d %>%
mutate(Calibracion = df_calibracion.calculada$Calibracion)
d %>%  ## no me estarian saliendo las leyendas, despues reviso
select(ConfMean,PC,Participant) %>%
# normalizo el promedio de confianza por sujeto para que este en una escala similar a la del desempeno
mutate(ConfMean = ConfMean/4, nr = row_number()) %>%
arrange(ConfMean) %>%
mutate(nr = row_number()) %>%
ggplot(aes(x= nr)) +
geom_point(aes(y=ConfMean), size = 2, color = "black") +
geom_point(aes(y=PC), size = 2, color = "grey")+
scale_x_continuous(expand = expansion(mult = c(0.01, 0.01))) +
scale_y_continuous(expand = expansion(mult = c(0.01, 0.1))) +
theme(axis.line = element_line(colour = "black"),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.border = element_blank(),
plot.margin = margin(1, 1,1, 1, "cm"),
legend.text =  element_text(size = 25),
legend.position = c(0.7, 0.2),
legend.background = element_blank(),
legend.key = element_blank(),
legend.title = element_blank(),
panel.background = element_blank(),
axis.text.x = element_text(size = 30),
axis.text.y = element_text(size = 30),
axis.title.x = element_blank(),
axis.title.y = element_blank())
hist(d$Calibracion)
model <- lm(Calibracion ~ DomainAntagonism +
DomainDetachment +
DomainDisinhibition +
DomainNegativeAffect +
DomainPsychoticism,
data=d)
summary(model)
model2 <- lm(Calibracion ~ DomainAntagonism +
DomainDetachment +
DomainDisinhibition +
DomainNegativeAffect +
DomainPsychoticism +
gender +
age,
data=d)
summary(model2)
str(d)
# saco las variables que no necesito
d %>%
select(!c(DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc,
gender)) %>%
as.matrix() %>%
heatmap()
library(corrplot)
install.packages("corrplot")
# saco las variables que no necesito
d.cor <- d %>%
select(!c(DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc,
gender)) %>%
as.matrix() %>%
heatmap()
# saco las variables que no necesito
d.cor <- d %>%
select(!c(DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc,
gender))
library(corrplot)
corrplot(cor(d.cor), method = "ellipse")
corrplot(cor(d.cor), method = "ellipse")
corrplot(cor(d.cor), type="upper", method = "ellipse")
corrplot(cor(d.cor), type="upper", method = "ellipse")
corrplot(cor(d.cor), type="upper", method = "ellipse")
cor(d.cor)
str(d.cor)
# saco las variables que no necesito
d.cor <- d %>%
select(!c(DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc,
gender,
Participant,
age,
Calibracion))
library(corrplot)
corrplot(cor(d.cor), type="upper", method = "ellipse")
cor(d.cor)
sum(cor(d.cor) > 0.3)
sum(cor(d.cor) > 0.1)
sum(cor(d.cor) > 0)
sum(cor(d.cor) > 0.5)
sum(cor(d.cor) > 0.7)
sum(cor(d.cor) > 0.5)
sum(cor(d.cor) > 0.6)
25*25
corrplot(cor(d.cor), type="upper", method = "ellipse", tl.srt=45)
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
load("./df_total_filtered.Rda")
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
load("./df_total_filtered.Rda")
df_calibracion <- df_total %>%
group_by(Participant, confidence_key) %>%
summarise(prop_correcta = mean(discrimination_is_correct)) %>%
rename(ConfidenceKey = confidence_key)
df_calibracion.calculada <- df_total %>%
pivot_longer(cols = starts_with("ConfKey")) %>%
distinct(Participant, name, .keep_all = TRUE) %>%
select(Participant, name, value) %>%
mutate(ConfidenceKey = as.integer(str_extract(name, "\\d"))) %>%
left_join(df_calibracion) %>%
drop_na() %>%
mutate(ConfidenceKey = (ConfidenceKey+2)/6) %>%
group_by(Participant) %>%
mutate(Conf.norm = value / sum(value)) %>%
mutate( preCalibracion = value*(prop_correcta - ConfidenceKey)**2) %>%
summarise(Calibracion  = mean(preCalibracion))
#Convierto el data frame por trials en un data frame por participantes
d <- df_total %>%
select(!c(RelyOn,
Problems,
ConfKey1,
ConfKey2,
ConfKey3,
ConfKey4,
discrimination_is_correct,
confidence_key,
trials,
PointDifference,
ReacTime_DiscTask,
ReacTime_ConfTask)) %>%
distinct(Participant,.keep_all = TRUE)
# le agrego la variable calibracion
d <- d %>%
mutate(Calibracion = df_calibracion.calculada$Calibracion)
library(tidyverse)
library(glmnet)
df_calibracion <- df_total %>%
group_by(Participant, confidence_key) %>%
summarise(prop_correcta = mean(discrimination_is_correct)) %>%
rename(ConfidenceKey = confidence_key)
df_calibracion.calculada <- df_total %>%
pivot_longer(cols = starts_with("ConfKey")) %>%
distinct(Participant, name, .keep_all = TRUE) %>%
select(Participant, name, value) %>%
mutate(ConfidenceKey = as.integer(str_extract(name, "\\d"))) %>%
left_join(df_calibracion) %>%
drop_na() %>%
mutate(ConfidenceKey = (ConfidenceKey+2)/6) %>%
group_by(Participant) %>%
mutate(Conf.norm = value / sum(value)) %>%
mutate( preCalibracion = value*(prop_correcta - ConfidenceKey)**2) %>%
summarise(Calibracion  = mean(preCalibracion))
#Convierto el data frame por trials en un data frame por participantes
d <- df_total %>%
select(!c(RelyOn,
Problems,
ConfKey1,
ConfKey2,
ConfKey3,
ConfKey4,
discrimination_is_correct,
confidence_key,
trials,
PointDifference,
ReacTime_DiscTask,
ReacTime_ConfTask)) %>%
distinct(Participant,.keep_all = TRUE)
# le agrego la variable calibracion
d <- d %>%
mutate(Calibracion = df_calibracion.calculada$Calibracion)
filepath <- root$find_file("Entrega_Final/d.Rda")
save(d,file = filepath)
library(tidyverse)
library(glmnet)
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
<<<<<<< HEAD
opt_alpha_lambda <- function(df){
# Creo los vectores que van a contener todos los lambdas, alphas y sus respectivos RMSE
alphas.usados <- c()
lambdas.usados <- c()
RMSE <- c()
# creo los alphas que vamos a usar
muchos.alphas <- seq(0,1, by = 0.1)
# itero por varios alphas
for (i in 1:length(muchos.alphas)) {
alpha.dado <- muchos.alphas[i]
# Hago LOOCV para elegir varios lambdas
lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
RMSE <- c(RMSE, lambdaOptimo_facetas$lambda.RMSE)
alphas.usados <- c(alphas.usados, rep(alpha.dado,length(lambdaOptimo_facetas$lambda.RMSE)))
lambdas.usados <- c(lambdas.usados,lambdaOptimo_facetas$lambdas)
}
df_alp_lambd_RMSE <- data.frame(alpha = alphas.usados,
lambda = lambdas.usados,
RMSE = RMSE)
return(df_alp_lambd_RMSE)
}
opt_alpha_lambda.df <- opt_alpha_lambda(d.regre.regul.facetas)
library(tidyverse)
library(glmnet)
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
<<<<<<< HEAD
library(tidyverse)
library(glmnet)
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
<<<<<<< HEAD
# voy a la carpeta del proyecto
root <- rprojroot::is_rstudio_project
basename(getwd())
# load the function to get the df list
load("./d.Rda")
library(tidyverse)
library(glmnet)
# saco las variables que no necesito
d.cor <- d %>%
select(!c(DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc,
gender,
Participant,
age,
Calibracion))
library(corrplot)
# ploteo la correlacion
corrplot(cor(d.cor), type="upper", method = "ellipse", tl.srt=45)
# me fijo cuantas correlaciones mayores a .6 hay
sum(cor(d.cor) > 0.6)
####
LOOCV.fun.glmnet <- function(df, alpha.dado){
### Primero creo una secuencua de posibles lambdas, desde un modelo desechable
# Guardo las observaciones de genero
y <- df$Calibracion
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
df.lambda <- df %>% select(!c(Calibracion,Participant))
# transformo en matrix
df.lambda.m <- df.lambda %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.lambda <- glmnet(df.lambda.m, y,
alpha = alpha.dado)
posibles_lambdas <- modelo.lambda$lambda
# creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
matriz.errores <- matrix(data=NA,nrow= nrow(df),
ncol= length(posibles_lambdas))
for (j in 1:nrow(df)){
# datos de entrenamiento (todos menos 1)
train <- df %>%
filter(Participant != df$Participant[j])
# agarro el dato que quedo para el testeo
test  <- anti_join(df, train, by = 'Participant')
# Guardo las observaciones de genero en entrenamiento y testeo (para entrenar el modelo y testearlo)
y.train <- train$Calibracion
y.test <- test$Calibracion
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
train <- train %>% select(!c(Calibracion,Participant))
test <- test %>% select(!c(Calibracion,Participant))
# transformo en matrix
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo con los datos de entrenamiento
modelo <- glmnet(train.m, y.train,
alpha = alpha.dado,
lambda = posibles_lambdas)
# hago prediccion sobre la data de testeo
matriz.errores[j,] <- modelo %>% predict(newx = test.m, type = "response")
}
# saco los root mean squared errors para cada lambda
lambda.RMSE <- sqrt(((colSums(matriz.errores))**2)/nrow(df))
list_return <- list("lambda.RMSE" = lambda.RMSE,
"lambdas" = posibles_lambdas)
return(list_return)
}
# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
select(!c(DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc,
gender))
opt_alpha_lambda <- function(df){
# Creo los vectores que van a contener todos los lambdas, alphas y sus respectivos RMSE
alphas.usados <- c()
lambdas.usados <- c()
RMSE <- c()
# creo los alphas que vamos a usar
muchos.alphas <- seq(0,1, by = 0.1)
# itero por varios alphas
for (i in 1:length(muchos.alphas)) {
alpha.dado <- muchos.alphas[i]
# Hago LOOCV para elegir varios lambdas
lambdaOptimo_facetas <- LOOCV.fun.glmnet(df, alpha.dado)
RMSE <- c(RMSE, lambdaOptimo_facetas$lambda.RMSE)
alphas.usados <- c(alphas.usados, rep(alpha.dado,length(lambdaOptimo_facetas$lambda.RMSE)))
lambdas.usados <- c(lambdas.usados,lambdaOptimo_facetas$lambdas)
}
df_alp_lambd_RMSE <- data.frame(alpha = alphas.usados,
lambda = lambdas.usados,
RMSE = RMSE)
return(df_alp_lambd_RMSE)
}
opt_alpha_lambda.df <- opt_alpha_lambda(d.regre.regul.facetas)
# tomo el lambda que tiene el menor error
index.opt.param <- which.min(opt_alpha_lambda.df$RMSE)
# Corro el modelo con el alpha optimo y el lambda que minimiza el error
lambda.optimo <- opt_alpha_lambda.df$lambda[index.opt.param]
alpha.optimo <- opt_alpha_lambda.df$alpha[index.opt.param]
### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$Calibracion
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(Calibracion,Participant))
# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.facetas <- glmnet(d.regre.regul.facetas.prepro.m, y,
alpha = alpha.optimo, lambda = lambda.optimo)
# me fijo el lambda optimo que me elije el modelo por si solo usando funciones de la libreria, para alpha = alpha.optimo
modelo.facetas2 <- glmnet(d.regre.regul.facetas.prepro.m, y,
alpha = alpha.optimo)
coef(modelo.facetas2)
set.seed(1010)
cvfit <- cv.glmnet(d.regre.regul.facetas.prepro.m,y, type.measure = "mse", nfolds = nrow(d.regre.regul.facetas))
cvfit$lambda.min
coef(cvfit, s = "lambda.min")
# veo que son parecidos al seleccionado con la funcion que cree
cvfit <- cv.glmnet(d.regre.regul.facetas.prepro.m,y,  alpha = alpha.optimo, type.measure = "mse", nfolds = nrow(d.regre.regul.facetas))
cvfit$lambda.min
lambda.optimo
modelo.facetas
coef(modelo.facetas)
coef(cvfit, s = "lambda.min")
modelo.facetas2 <- glmnet(d.regre.regul.facetas.prepro.m, y,
alpha = alpha.optimo)
coef(modelo.facetas2)
cvfit$lambda.min
