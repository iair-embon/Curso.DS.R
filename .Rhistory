predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
matriz.errores[j,] <- predicted.classes == y.test
}
# saco los root mean squared errors para cada lambda (en principio, solo vamos a usar accuracy)
# lambda.RMSE <- sqrt(((rowSums(matriz.errores))**2)/nrow(df))
return(matriz.errores)
}
lambdaOptimo_facetas_ridge <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0)
lambdaOptimo_facetas_ridge %>% apply(2, mean) %>% plot(type ='l', log = 'x')
View(lambdaOptimo_facetas_ridge)
accuracy_lambdas <- colMeans(lambdaOptimo_facetas_ridge)
accuracy_lambdas
lambdaOptimo_facetas_ridge %>% apply(2, mean) %>% plot(type ='l', log = 'x')
list_return <- list("matriz.errores" = matriz.errores,
"lambdas" = posibles_lambdas)
LOOCV.fun.glmnet <- function(df, alpha.dado){
### Primero creo una secuencua de posibles lambdas, desde un modelo desechable
# Guardo las observaciones de genero
y <- df$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
df.lambda <- df %>% select(!c(gender,Participant))
# transformo en matrix
df.lambda.m <- df.lambda %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.lambda <- glmnet(df.lambda.m, y , family = "binomial",
alpha = alpha.dado)
posibles_lambdas <- modelo.lambda$lambda
# creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
matriz.errores <- matrix(data=NA,nrow= nrow(df),
ncol= length(posibles_lambdas))
for (j in 1:nrow(df)){
# datos de entrenamiento (todos menos 1)
train <- df %>%
filter(Participant != df$Participant[j])
# agarro el dato que quedo para el testeo
test  <- anti_join(df, train, by = 'Participant')
# Guardo las observaciones de genero en entrenamiento y testeo (para entrenar el modelo y testearlo)
y.train <- train$gender
y.test <- test$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
train <- train %>% select(!c(gender,Participant))
test <- test %>% select(!c(gender,Participant))
# transformo en matrix
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo con los datos de entrenamiento
modelo <- glmnet(train.m, y.train, family = "binomial",
alpha = alpha.dado, lambda = posibles_lambdas)
# hago prediccion sobre la data de testeo
probabilities <- modelo %>% predict(newx = test.m, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
matriz.errores[j,] <- predicted.classes == y.test
}
# saco los root mean squared errors para cada lambda (en principio, solo vamos a usar accuracy)
# lambda.RMSE <- sqrt(((rowSums(matriz.errores))**2)/nrow(df))
list_return <- list("matriz.errores" = matriz.errores,
"lambdas" = posibles_lambdas)
return(matriz.errores)
}
LOOCV.fun.glmnet <- function(df, alpha.dado){
### Primero creo una secuencua de posibles lambdas, desde un modelo desechable
# Guardo las observaciones de genero
y <- df$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
df.lambda <- df %>% select(!c(gender,Participant))
# transformo en matrix
df.lambda.m <- df.lambda %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.lambda <- glmnet(df.lambda.m, y , family = "binomial",
alpha = alpha.dado)
posibles_lambdas <- modelo.lambda$lambda
# creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
matriz.errores <- matrix(data=NA,nrow= nrow(df),
ncol= length(posibles_lambdas))
for (j in 1:nrow(df)){
# datos de entrenamiento (todos menos 1)
train <- df %>%
filter(Participant != df$Participant[j])
# agarro el dato que quedo para el testeo
test  <- anti_join(df, train, by = 'Participant')
# Guardo las observaciones de genero en entrenamiento y testeo (para entrenar el modelo y testearlo)
y.train <- train$gender
y.test <- test$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
train <- train %>% select(!c(gender,Participant))
test <- test %>% select(!c(gender,Participant))
# transformo en matrix
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo con los datos de entrenamiento
modelo <- glmnet(train.m, y.train, family = "binomial",
alpha = alpha.dado, lambda = posibles_lambdas)
# hago prediccion sobre la data de testeo
probabilities <- modelo %>% predict(newx = test.m, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
matriz.errores[j,] <- predicted.classes == y.test
}
# saco los root mean squared errors para cada lambda (en principio, solo vamos a usar accuracy)
# lambda.RMSE <- sqrt(((rowSums(matriz.errores))**2)/nrow(df))
list_return <- list("matriz.errores" = matriz.errores,
"lambdas" = posibles_lambdas)
return(matriz.errores)
}
lambdaOptimo_facetas_ridge <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0)
# lo ploteo
lambdaOptimo_facetas_ridge %>% apply(2, mean) %>% plot(type ='l', log = 'x')
LOOCV.fun.glmnet <- function(df, alpha.dado){
### Primero creo una secuencua de posibles lambdas, desde un modelo desechable
# Guardo las observaciones de genero
y <- df$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
df.lambda <- df %>% select(!c(gender,Participant))
# transformo en matrix
df.lambda.m <- df.lambda %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.lambda <- glmnet(df.lambda.m, y , family = "binomial",
alpha = alpha.dado)
posibles_lambdas <- modelo.lambda$lambda
# creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
matriz.errores <- matrix(data=NA,nrow= nrow(df),
ncol= length(posibles_lambdas))
for (j in 1:nrow(df)){
# datos de entrenamiento (todos menos 1)
train <- df %>%
filter(Participant != df$Participant[j])
# agarro el dato que quedo para el testeo
test  <- anti_join(df, train, by = 'Participant')
# Guardo las observaciones de genero en entrenamiento y testeo (para entrenar el modelo y testearlo)
y.train <- train$gender
y.test <- test$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
train <- train %>% select(!c(gender,Participant))
test <- test %>% select(!c(gender,Participant))
# transformo en matrix
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo con los datos de entrenamiento
modelo <- glmnet(train.m, y.train, family = "binomial",
alpha = alpha.dado, lambda = posibles_lambdas)
# hago prediccion sobre la data de testeo
probabilities <- modelo %>% predict(newx = test.m, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
matriz.errores[j,] <- predicted.classes == y.test
}
# saco los root mean squared errors para cada lambda (en principio, solo vamos a usar accuracy)
# lambda.RMSE <- sqrt(((rowSums(matriz.errores))**2)/nrow(df))
list_return <- list("matriz.errores" = matriz.errores,
"lambdas" = posibles_lambdas)
return(list_return)
}
lambdaOptimo_facetas_ridge <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0)
# lo ploteo
lambdaOptimo_facetas_ridge %>% apply(2, mean) %>% plot(type ='l', log = 'x')
# lo ploteo
matriz.errores <- lambdaOptimo_facetas_ridge$matriz.errores
matriz.errores %>% apply(2, mean) %>% plot(type ='l', log = 'x')
accuracy_lambdas <- colMeans(lambdaOptimo_facetas_ridge$lambdas)
accuracy_lambdas <- colMeans(lambdaOptimo_facetas_ridge$lambdas)
# saco la proporcion de aciertos
lambdas <- lambdaOptimo_facetas_ridge$lambdas
accuracy_lambdas <- colMeans(lambdas)
lambdas
# saco la proporcion de aciertos
accuracy_lambdas <- colMeans(matriz.errores)
accuracy_lambdas
# tomo el lambda que tiene mayor porporcion de aciertos
index.lambda <- which.max(accuracy_lambdas)
lambdaOptimo_facetas_ridge$lambdas
index.lambda
lambda.optimo <- lambdaOptimo_facetas_ridge$lambdas[index.lambda]
lambda.optimo
# Corro el modelo y obtengo el lambda
modelo.facetas_ridge <- glmnet(d.regre.regul.facetas.prepro.m, y , family = "binomial",
alpha = 0, lambda = lambda.optimo)
# lo ploteo
matriz.errores <- lambdaOptimo_facetas_ridge$matriz.errores
matriz.errores %>% apply(2, mean) %>% plot(type ='l', log = 'x')
# saco la proporcion de aciertos
accuracy_lambdas <- colMeans(matriz.errores)
# tomo el lambda que tiene mayor porporcion de aciertos
index.lambda <- which.max(accuracy_lambdas)
lambda.optimo <- lambdaOptimo_facetas_ridge$lambdas[index.lambda]
### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(gender,Participant))
# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.facetas_ridge <- glmnet(d.regre.regul.facetas.prepro.m, y , family = "binomial",
alpha = 0, lambda = lambda.optimo)
coef(modelo.facetas_ridge)
lambdaOptimo_facetas_lasso <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 1)
# lo ploteo
matriz.errores <- lambdaOptimo_facetas_lasso$matriz.errores
matriz.errores %>% apply(2, mean) %>% plot(type ='l', log = 'x')
# saco la proporcion de aciertos
accuracy_lambdas <- colMeans(matriz.errores)
# tomo el lambda que tiene mayor porporcion de aciertos
index.lambda <- which.max(accuracy_lambdas)
lambda.optimo <- lambdaOptimo_facetas_lasso$lambdas[index.lambda]
### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$gender
d.regre.regul.facetas$gender
table(d.regre.regul.facetas$gender)
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(gender,Participant))
# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.facetas_lasso <- glmnet(d.regre.regul.facetas.prepro.m, y , family = "binomial",
alpha = 0, lambda = lambda.optimo)
lambda.optimo
# Corro el modelo y obtengo el lambda
modelo.facetas_lasso <- glmnet(d.regre.regul.facetas.prepro.m, y , family = "binomial",
alpha = 1, lambda = lambda.optimo)
coef(modelo.facetas_lasso)
lambdaOptimo_facetas_elasticNet <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0.5)
# lo ploteo
matriz.errores <- lambdaOptimo_facetas_elasticNet$matriz.errores
matriz.errores %>% apply(2, mean) %>% plot(type ='l', log = 'x')
# saco la proporcion de aciertos
accuracy_lambdas <- colMeans(matriz.errores)
accuracy_lambdas
# tomo el lambda que tiene mayor porporcion de aciertos
index.lambda <- which.max(accuracy_lambdas)
lambda.optimo <- lambdaOptimo_facetas_elasticNet$lambdas[index.lambda]
lambda.optimo
### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$gender
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(gender,Participant))
# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()
lambda.optimo
# Corro el modelo y obtengo el lambda
modelo.facetas_elasticNet <- glmnet(d.regre.regul.facetas.prepro.m, y , family = "binomial",
alpha = 0.5, lambda = lambda.optimo)
coef(modelo.facetas_elasticNet)
library(tidyverse)
library(glmnet)
library(tidyverse)
# load the function to get the df list
load("./df_total_filtered.Rda")
df_calibracion <- df_total %>%
group_by(Participant, confidence_key) %>%
summarise(prop_correcta = mean(discrimination_is_correct)) %>%
rename(ConfidenceKey = confidence_key)
df_calibracion.calculada <- df_total %>%
pivot_longer(cols = starts_with("ConfKey")) %>%
distinct(Participant, name, .keep_all = TRUE) %>%
select(Participant, name, value) %>%
mutate(ConfidenceKey = as.integer(str_extract(name, "\\d"))) %>%
left_join(df_calibracion) %>%
drop_na() %>%
mutate(ConfidenceKey = (ConfidenceKey+2)/6) %>%
group_by(Participant) %>%
mutate(Conf.norm = value / sum(value)) %>%
mutate( preCalibracion = value*(prop_correcta - ConfidenceKey)**2) %>%
summarise(Calibracion  = mean(preCalibracion))
ggplot(
data = df_calibracion.calculada,
aes(x = ConfidenceKey, y = prop_correcta)) + geom_jitter(width = 0.02) + geom_smooth(method = "lm")
df_calibracion <- df_total %>%
group_by(Participant, confidence_key) %>%
summarise(prop_correcta = mean(discrimination_is_correct)) %>%
rename(ConfidenceKey = confidence_key)
df_calibracion.calculada <- df_total %>%
pivot_longer(cols = starts_with("ConfKey")) %>%
distinct(Participant, name, .keep_all = TRUE) %>%
select(Participant, name, value) %>%
mutate(ConfidenceKey = as.integer(str_extract(name, "\\d"))) %>%
left_join(df_calibracion) %>%
drop_na() %>%
mutate(ConfidenceKey = (ConfidenceKey+2)/6) %>%
group_by(Participant) %>%
mutate(Conf.norm = value / sum(value)) %>%
mutate( preCalibracion = value*(prop_correcta - ConfidenceKey)**2) %>%
summarise(Calibracion  = mean(preCalibracion))
ggplot(mapping = aes(df_calibracion.calculada$Calibracion, d$ConfMean))+
geom_smooth(method = "lm") + geom_point()
d <- df_total %>%
select(!c(RelyOn,
Problems,
ConfKey1,
ConfKey2,
ConfKey3,
ConfKey4,
discrimination_is_correct,
confidence_key,
trials,
PointDifference,
ReacTime_DiscTask,
ReacTime_ConfTask)) %>%
distinct(Participant,.keep_all = TRUE)
df_calibracion.calculada$Calibracion
d <- d %>%
mutate(Calibracion = df_calibracion.calculada$Calibracion)
# veo cuantos hay
d %>%
summarise(n= sum(Calibracion))
hist(d$Calibracion)
table(d$Calibracion)
sort(d$Calibracion)
model <- lm(Calibracion ~ DomainAntagonism +
DomainDetachment +
DomainDisinhibition +
DomainNegativeAffect +
DomainPsychoticism,
data=d)
summary(model)
model2 <- lm(Calibracion ~ DomainAntagonism +
DomainDetachment +
DomainDisinhibition +
DomainNegativeAffect +
DomainPsychoticism +
gender +
age,
data=d)
summary(model2)
LOOCV.fun.glmnet <- function(df, alpha.dado){
### Primero creo una secuencua de posibles lambdas, desde un modelo desechable
# Guardo las observaciones de genero
y <- df$Calibracion
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
df.lambda <- df %>% select(!c(Calibracion,Participant))
# transformo en matrix
df.lambda.m <- df.lambda %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.lambda <- glmnet(df.lambda.m, y,
alpha = alpha.dado)
posibles_lambdas <- modelo.lambda$lambda
# creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
matriz.errores <- matrix(data=NA,nrow= nrow(df),
ncol= length(posibles_lambdas))
for (j in 1:nrow(df)){
# datos de entrenamiento (todos menos 1)
train <- df %>%
filter(Participant != df$Participant[j])
# agarro el dato que quedo para el testeo
test  <- anti_join(df, train, by = 'Participant')
# Guardo las observaciones de genero en entrenamiento y testeo (para entrenar el modelo y testearlo)
y.train <- train$Calibracion
y.test <- test$Calibracion
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
train <- train %>% select(!c(Calibracion,Participant))
test <- test %>% select(!c(Calibracion,Participant))
# transformo en matrix
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo con los datos de entrenamiento
modelo <- glmnet(train.m, y.train,
alpha = alpha.dado,
lambda = posibles_lambdas)
# hago prediccion sobre la data de testeo
matriz.errores[j,] <- modelo %>% predict(newx = test.m, type = "response")
}
# saco los root mean squared errors para cada lambda
lambda.RMSE <- sqrt(((rowSums(matriz.errores))**2)/nrow(df))
list_return <- list("lambda.RMSE" = lambda.RMSE,
"lambdas" = posibles_lambdas)
return(list_return)
}
# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
select(!c(DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc,
gender,
ConfMean.norm))
str(d)
# saco las variables que no me interesan para esta parte de facetas
d.regre.regul.facetas <- d %>%
select(!c(DomainNegativeAffect,
DomainDetachment,
DomainAntagonism,
DomainDisinhibition,
DomainPsychoticism,
PC,
ConfMean,
ConfSD,
ReacTimeMean_DiscTask,
ReacTimeSD_DiscTask,
ReacTimeMean_ConfTask,
ReacTimeSD_ConfTask,
mc,
gender))
lambdaOptimo_facetas_ridge <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0)
lambdaOptimo_facetas_ridge <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0)
lambdaOptimo_facetas_ridge$lambda.RMSE
lambdaOptimo_facetas_ridge$lambdas
which.max(lambdaOptimo_facetas_ridge$lambda.RMSE)
which.max(lambdaOptimo_facetas_ridge$lambda.RMSE)
# lo ploteo
plot(lambdaOptimo_facetas_ridge$lambda.RMSE,type ='l', log = 'x')
# tomo el lambda que tiene el menor error
index.lambda <- which.min(lambdaOptimo_facetas_ridge$lambda.RMSE)
lambda.optimo <- lambdaOptimo_facetas_ridge$lambdas[index.lambda]
lambda.optimo
index.lambda
lambdaOptimo_facetas_ridge$lambdas
lambdaOptimo_facetas_ridge$lambda.RMSE
LOOCV.fun.glmnet <- function(df, alpha.dado){
### Primero creo una secuencua de posibles lambdas, desde un modelo desechable
# Guardo las observaciones de genero
y <- df$Calibracion
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
df.lambda <- df %>% select(!c(Calibracion,Participant))
# transformo en matrix
df.lambda.m <- df.lambda %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.lambda <- glmnet(df.lambda.m, y,
alpha = alpha.dado)
posibles_lambdas <- modelo.lambda$lambda
# creo una matriz en donde se van a ir guardando los errores de cada lambda y cada vez que hago LOOCV
matriz.errores <- matrix(data=NA,nrow= nrow(df),
ncol= length(posibles_lambdas))
for (j in 1:nrow(df)){
# datos de entrenamiento (todos menos 1)
train <- df %>%
filter(Participant != df$Participant[j])
# agarro el dato que quedo para el testeo
test  <- anti_join(df, train, by = 'Participant')
# Guardo las observaciones de genero en entrenamiento y testeo (para entrenar el modelo y testearlo)
y.train <- train$Calibracion
y.test <- test$Calibracion
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
train <- train %>% select(!c(Calibracion,Participant))
test <- test %>% select(!c(Calibracion,Participant))
# transformo en matrix
train.m <- train %>% data.matrix()
test.m <- test %>% data.matrix()
# corro el modelo con los datos de entrenamiento
modelo <- glmnet(train.m, y.train,
alpha = alpha.dado,
lambda = posibles_lambdas)
# hago prediccion sobre la data de testeo
matriz.errores[j,] <- modelo %>% predict(newx = test.m, type = "response")
}
# saco los root mean squared errors para cada lambda
lambda.RMSE <- sqrt(((colSums(matriz.errores))**2)/nrow(df))
list_return <- list("lambda.RMSE" = lambda.RMSE,
"lambdas" = posibles_lambdas)
return(list_return)
}
lambdaOptimo_facetas_ridge <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0)
lambdaOptimo_facetas_ridge <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0)
# lo ploteo
plot(lambdaOptimo_facetas_ridge$lambda.RMSE,type ='l', log = 'x')
lambdaOptimo_facetas_ridge$lambda.RMSE
# lo ploteo
plot(lambdaOptimo_facetas_ridge$lambda.RMSE,type ='l', log = 'x')
# tomo el lambda que tiene el menor error
index.lambda <- which.min(lambdaOptimo_facetas_ridge$lambda.RMSE)
lambda.optimo <- lambdaOptimo_facetas_ridge$lambdas[index.lambda]
lambda.optimo
### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$Calibracion
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(Calibracion,Participant))
# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.facetas_ridge <- glmnet(d.regre.regul.facetas.prepro.m, y,
alpha = 0, lambda = lambda.optimo)
coef(modelo.facetas_ridge)
lambdaOptimo_facetas_lasso <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 1)
# lo ploteo
plot(lambdaOptimo_facetas_lasso$lambda.RMSE,type ='l', log = 'x')
# tomo el lambda que tiene el menor error
index.lambda <- which.min(lambdaOptimo_facetas_lasso$lambda.RMSE)
lambda.optimo <- lambdaOptimo_facetas_lasso$lambdas[index.lambda]
### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$Calibracion
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(Calibracion,Participant))
# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.facetas_lasso <- glmnet(d.regre.regul.facetas.prepro.m, y,
alpha = 1, lambda = lambda.optimo)
coef(modelo.facetas_lasso)
lambdaOptimo_facetas_ElasticNet <- LOOCV.fun.glmnet(d.regre.regul.facetas, alpha.dado = 0.5)
# lo ploteo
plot(lambdaOptimo_facetas_ElasticNet$lambda.RMSE,type ='l', log = 'x')
# tomo el lambda que tiene el menor error
index.lambda <- which.min(lambdaOptimo_facetas_ElasticNet$lambda.RMSE)
lambda.optimo <- lambdaOptimo_facetas_ElasticNet$lambdas[index.lambda]
### corro la regresion con el lambda optimo
y <- d.regre.regul.facetas$Calibracion
# ahora les saco genero y Participant (ya que no tienen que ir como predictores)
d.regre.regul.facetas.prepro <- d.regre.regul.facetas %>% select(!c(Calibracion,Participant))
# transformo en matrix
d.regre.regul.facetas.prepro.m <- d.regre.regul.facetas.prepro %>% data.matrix()
# Corro el modelo y obtengo el lambda
modelo.facetas_ElasticNet <- glmnet(d.regre.regul.facetas.prepro.m, y,
alpha = 0.5, lambda = lambda.optimo)
coef(modelo.facetas_ElasticNet)
